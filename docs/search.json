[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "System Dynamics",
    "section": "",
    "text": "General Information\nThis is a living document created from markdown and executable code. Feel free to reach out if you find typos or have suggestions. It’s a passion project though, so my response time may vary.\nMy Email: benjamin.aziel@cooper.edu\nCourse Description: An introductory course to the mathematical modeling of systems. Topics include mechanical elements and systems, electric circuits and analogous systems, fluid elements and systems, analysis of systems using transfer functions, state space equations, analog simulation and digital simulation. Also covered are block diagrams, Laplace transforms, and linear system analysis. Computer projects will be assigned that will use MATLAB/Python.\nCourse Instructor: Dirk M. Luchtenburg (dirk.luchtenburg@cooper.edu)\n\n\nPatch Notes/Detritus\nTo-Do:\n\nTalk about underlining vs boldfacing vectors. And start doing the latter!\n\\(\\S\\) 4.4\nFlesh out Chapter 6\nFinish Chapter 7\n\nLog:\n\n05.22.23 - Transplanted everything from the original LaTeX file here except for pictures. Some additional formatting changes needed, and a LOT of editing, but things look pretty good…\n05.18.23 - Made the jump from a LaTeX document on Github to Quarto at Prof. Luchtenburg’s recommendation. It’s pretty cool…can embed inline code and whatnot!"
  },
  {
    "objectID": "ch1.html#first-ramblings",
    "href": "ch1.html#first-ramblings",
    "title": "1  Course Motivation and Overview",
    "section": "1.1 First Ramblings",
    "text": "1.1 First Ramblings\nThe course is called Systems Engineering in the course catalog, but Prof. Luchtenburg calls it System Dynamics instead. It’s a more apt name for what the course actually covers; if you look up Systems Engineering you’ll find a completely different subject.\nThe course text is Ogata’s System Dynamics, which doesn’t fit particularly well for the course. Most feedback control textbooks, like Nise, start with a few chapters covering dynamic modeling and response, but they tend not to be very in depth. I can provide PDFs if you can’t find them yourselves. Read the syllabus, it’s pretty in depth.\nProf. Luchtenburg should put his notes up in the MS Teams Class Notebook and record his lectures (if he hasn’t given up using Microsoft Teams yet). Your mileage may vary if you don’t bother coming to class, though; the audio quality in the recordings isn’t that great and the notes can be less detailed than the lectures themselves.\nThis document is a living document, which means I’ll continue editing it as I see fit. I reserve the right to include material that may not be covered in the course, but better prepares you for concepts that may seem like they come out-of-the-blue otherwise.\nI have this lousy habit of writing in the fourth person and cursing in my writing. Apologies in advance."
  },
  {
    "objectID": "ch1.html#why-model",
    "href": "ch1.html#why-model",
    "title": "1  Course Motivation and Overview",
    "section": "1.2 Why Model?",
    "text": "1.2 Why Model?\nTo start off, let’s define a model. A mathematical model of a system is a set of differential equations that allows us to predict how a system behaves under different conditions. By creating a model, we can use equations and principles to describe a system’s present behavior, identify key parameters that affect the system, and make educated guesses as to how the system will behave in the future.\nYou may have covered some rudimentary modeling in Ma111 or Ma240, where it was probably crammed in to satisfy those annoying kids that go “wHEN ARe we ever gOINg to usE tHIS iN ReAl LIfE”. The methods we’ll cover in this course will be more robust than simply going off a given formula.\nSomething we’ll exploit heavily a lot in this course is the principle of analogical models, or generic representations of common physical phenomena. This turns out to be really useful because it provides a convenient and consistent way to represent and analyze complex systems that involve different types of “stuff”. Say you’re faced with a fluid flow system, and you haven’t taken a fluid mechanics course yet. Using methods introduced in this course, we will be able to convert this system into more familiar, yet equivalent, like a mass-spring system or a series circuit. Using these analogies allows us to apply the same concepts and mathematical tools to different types of systems, which can greatly simplify the analysis and design process.\nTo conclude, modeling is a powerful tool that, if mastered, will allow you to understand, predict, and (as we’ll see in ME351 next semester) control the behavior of physical systems, and it has many practical applications in engineering, physics, and other fields.\nDon’t suck at it."
  },
  {
    "objectID": "ch2.html#preface",
    "href": "ch2.html#preface",
    "title": "2  The First Order",
    "section": "Preface",
    "text": "Preface\nWe’ll grow more accustomed to the idea of analogical models after modeling a few simple systems. Let’s start by throwing out some fundamental systems and developing intuition to dive into simplified models.\n\nEmptying a water tank\nCooling of a lightbulb\nDischarge of an RC circuit"
  },
  {
    "objectID": "ch2.html#gradients-make-stuff-flow",
    "href": "ch2.html#gradients-make-stuff-flow",
    "title": "2  The First Order",
    "section": "2.1 Gradients Make Stuff Flow",
    "text": "2.1 Gradients Make Stuff Flow\nA cylindrical tank has a cross-sectional area of \\(A\\), and an outflow rate of \\(Q_\\text{out}\\). The water height is governed by the function \\(h(t)\\). The pressure outside the tank is \\(P_{\\infty}\\), and the fluid has a density of \\(\\rho\\). Can we derive a governing equation for this system in terms of \\(\\Delta P = P - P_{\\infty}\\), where \\(P(t)\\) is the pressure at the bottom of the tank?\n\nFirst off, because the tank is cylindrical, it’s apparent that the volume \\(V(t)\\) of water in the tank is proportional to the value of \\(h(t)\\).\n\\[V(t) = A h(t)\\]\nBecause of conservation of mass, we know the rate at which the volume is changing is the difference between the inflow and the outflow.\n\\[\\frac{d}{dt} V(t) = \\dot{V} = 0 -Q_\\text{out} = -Q_\\text{out} \\tag{1}\\]\nThat’s not very useful yet. Let’s leverage some prior circuits knowledge here…charge moves because of a voltage difference \\(\\Delta V\\), and comparably, fluid moves because of a pressure difference.1 Ohm’s law! We’ll come back to that, but the main takeaway here is that the outflow \\(Q_\\text{out}\\) is related to the difference between the pressure inside the tank \\(P(t)\\) and the atmospheric pressure \\(P_\\infty\\) by a “resistance” value \\(R\\).\nThat circuits analogy comes in handy really often, because it turns out Ohm’s law translates directly into fluid flow.\n\\[\\Delta V = V - V_0 = IR\\] \\[\\Delta P = P(t) - P_\\infty = Q_\\text{out} R \\tag{2}\\]\nThese are called constitutive equations, or relationships between physical quantities that establish a connection between a material’s internal response (like stress, strain, or deformation) and the external factors that influence it (like temperature, pressure, or applied loads).\nWe’ll generalize a bit soon, but for now I understand if you don’t get it. It’s still very hand-wavey.\nLet’s leverage some hydrostatics now. Assuming the tank is open to the atmosphere at the top, we can derive an expression for \\(\\Delta P\\) using the hydrostatic pressure equation \\(\\Delta P = \\rho g \\Delta h\\).\n\\[\\Delta P = P(t) - P_\\infty = \\rho g \\left(h(t) \\right) = \\frac{\\rho g V}{A}\\tag{3}\\]\nDifferentiating equation (3) yields the following:\n\\[ \\dot{P} = \\frac{\\rho g \\dot{V}}{A} \\]\nUsing equations (1) and (2), we can manipulate this equation into a differential equation in terms of pressure differences.\n\\[ \\dot{P} = \\frac{\\rho g \\left(- Q_\\text{out} \\right)}{A} = \\frac{- \\rho g \\Delta P}{A R}\\]\n\\[\\dot{P} + \\frac{\\rho g}{A R} \\Delta P = 0\\]\n\\[R \\left( \\frac{A}{\\rho g}\\right) \\dot{P} + \\Delta P = 0\\]\nThis is a neat little differential equation. It looks like the equation for an RC circuit if you’ve seen those before, with the voltage differences swapped out for pressure differences. To really drive this comparison home, we define a “capacitance” \\(C = \\frac{A}{\\rho g}\\) and slot it into our governing equation.\n\\[\\boxed{RC \\dot{P} + \\Delta P = 0}\\]\nPerfect. Note that this isn’t the only possible governing equation of the system - it’s also possible to find a differential equation in terms of volume \\(V(t)\\). Give it a go!\nLet’s move onto a second example: the cooling of a lightbulb. When we shut off power to the lightbulb, how can we measure its temperature as it cools to room temperature?\n\nThe bulb is initially very hot (with temperature \\(T\\)) compared to its environment (which has temperature \\(T_\\infty\\)). Heat is flowing outwards at \\(q_\\text{out}\\). This is seeming very familiar…a temperature difference is driving heat to leave through the resistance \\(R\\) of the bulb.\nLet’s go through the steps again. Energy’s being conserved here, so we use the capacitive relationship relating accumulated heat \\(Q\\) and temperature \\(T\\) from ESC330:\n\\[\\Delta Q = C \\Delta T\\]\nDifferentiate across the board…\n\\[\\frac{d}{dt} \\left(C \\Delta T \\right) = C\\dot{T} = -q_\\text{out}\\]\nAnd now we’re just chugging through the motions. Next is another constitutive relationship (which looks shudderingly close to Ohm’s law!):\n\\[\\Delta T = T - T_\\infty = q_\\text{out} R\\]\nWe combine the last two equations and construct:\n\\[\\boxed{RC \\dot{T} + \\Delta T = 0}\\]\nAgain. Familiar. Very familiar. Maybe there’s some unifying theory in the background here. We’ll generalize that equation to what we call its canonical form \\(\\tau \\dot{y} + y = 0\\), a first order differential equation. Let’s throw in an initial condition \\(y(0)=y_0\\) just so we don’t have any undetermined constants at the end.\nTo solve this differential equation, we’ll guess a solution \\(y(t) = ce^{\\alpha t}\\), find its time derivative \\(\\dot{y}(t) = \\alpha ce^{\\alpha t} = \\alpha y\\), and plug in.\n\\[\\tau \\dot{y} + y = 0\\] \\[\\tau \\alpha e^{\\alpha t} + e^{\\alpha t} = 0\\] \\[(\\tau \\alpha + 1) \\; e^{\\alpha t} = 0\\] \\[\\alpha = -\\frac{1}{\\tau}\\] \\[y(t) = ce^{-\\frac{t}{\\tau}} = y_0 \\; e^{-\\frac{t}{\\tau}}\\]\nIf you look at the graph below, it’s just exponential decay from \\((0, y_0)\\). We call \\(\\tau\\) the time constant of the system, and it’s commonly used to describe how quickly an exponential decays or grows. Different systems have different time constants. (Notably, \\(RC\\) always has units of time). The smaller the time constant, the faster the decay. (Assume for the figure below that \\(\\tau_1 = 10\\) and \\(\\tau_2 = 5\\).)\nSo what happens when we set \\(t=\\tau\\)? Let’s plug it in and find out.\n\\[y(\\tau) = y_0 e^{-\\frac{\\tau}{\\tau}} = y_0 e^{-1}\\]\nSo the time constant is the time at which the system response has decayed to \\(y_0 e^{-1}\\), or approximately 37% of its initial value. We can also reframe this definition as, “the time constant is the time at which the system response has lost approximately 63% of its initial value”."
  },
  {
    "objectID": "ch2.html#the-rc-circuit-and-final-generalization",
    "href": "ch2.html#the-rc-circuit-and-final-generalization",
    "title": "2  The First Order",
    "section": "2.2 The RC Circuit and Final Generalization",
    "text": "2.2 The RC Circuit and Final Generalization\nSay we have an RC circuit with a full capacitor.\nThe outflow of charge from the capacitor is represented as a negative current: \\[\\dot{q} = -I_\\text{out}\\]\nHere’s Ohm’s law: \\[\\Delta V = I_\\text{out} R = -\\dot{q} R\\] \\[\\dot{q} = -\\frac{\\Delta V}{R}\\]\nFinally, we deal in the capacitive relationship (from Ph213): \\[q = C\\Delta V\\]\nWe differentiate the capacitive relationship in order to set these equations equal to each other and get:\n\\[C\\dot{V} = -\\frac{\\Delta V}{R}\\] \\[\\boxed{RC \\dot{V} + \\Delta V = 0}\\]\nwhich is the same equation we’ve gotten before. (Notably, we don’t have to have this equation in terms of the voltage difference; as you’ll see in ESC221 this semester, there’s a form of the equation in terms of current as well.)\nFinal takeaways:\n\nMost first order systems we’ll analyze in this class are the same mathematically!\nLevel differences (gradients) make stuff flow.\n\n“Stuff” isn’t the greatest word for something like this, (maybe quantity or ‘energy’ instead?) but that’s the best we have. Stuff can be stored, like charge in a capacitor, or fluid in a tank, or heat in a reservoir. However, by generalizing these quantities, we can create widely applicable rules for modeling first order systems.\n\\[\\text{Stuff} = \\text{Capacitance} \\times \\text{Level Difference}\\] \\[\\text{Level Difference} = \\text{Flow of Stuff} \\times \\text{Resistance}\\]\nAlso conservation. That’s a biggie. \\[\\text{Rate of Change of Stuff} = \\text{Inflow} - \\text{Outflow}\\]\nWe’ve only discussed scenarios where there isn’t anything flowing in thus far. In these cases, to solve nonhomogeneous differential equations, we’ll have to use more specialized methods from Ma240 instead of guessing and praying, like the Laplace transform or the method of undetermined coefficients (or as I affectionately call it, MUC)."
  },
  {
    "objectID": "ch2.html#lets-throw-in-an-input",
    "href": "ch2.html#lets-throw-in-an-input",
    "title": "2  The First Order",
    "section": "2.3 Let’s Throw in an Input",
    "text": "2.3 Let’s Throw in an Input\nA more simple form of the governing equation for one of these first order systems is:\n\\[\\tau \\dot{y} + y = ku\\]\nwhen we have a constant input. Think of it as turning on a light switch at time \\(t=0\\). \\(k\\) is just a scale factor, and \\(u = u_s(t)\\), where \\(u_s\\) is the unit step function, which is just \\(0\\) when \\(t&lt;0\\) and \\(1\\) when \\(t&gt;0\\).2\n\\[y(t) = ce^{-\\frac{t}{\\tau}} + k\\]\nFor the initial condition \\(y(0) = y_0\\), the undetermined coefficient \\(c=y_0 - k\\). Here’s our updated solution:\n\\[y(t) = y_0 e^{-\\frac{t}{\\tau}} + k(1-e^{-\\frac{t}{\\tau}})\\]\nWhen we graph this function for \\(y_0 = 0\\), we see that it gradually grows towards \\(y=k\\) as \\(t\\to\\infty\\). Now we can analyze exponential growth. You see this behavior everywhere, like when you change a thermostat setting and the temperature slowly creeps towards your choice. This is what we call a step response.\nHow could we find the time constant of this response? Let’s take a look at what happens to \\(y(t)\\) at \\(t=\\tau\\).\n\\[y(\\tau) = y_0 e^{-\\frac{\\tau}{\\tau}} + k(1-e^{-\\frac{\\tau}{\\tau}})= y_0 e^{-1} + k(1-e^{-1})\\]\nWhen we set \\(y_0 = 0\\), this further simplifies to:\n\\[y(\\tau) = k(1-e^{-1}) \\approx 0.63 k\\]\nFor this system, at \\(t=\\tau\\), the system response will have accumulated 63% of its steady state value.\nThe step input is just one of the test inputs we usually use; we’ll look at a few more as the course progresses (such as sinusoidal waves, delta functions, etc.)."
  },
  {
    "objectID": "ch2.html#footnotes",
    "href": "ch2.html#footnotes",
    "title": "2  The First Order",
    "section": "",
    "text": "Note that \\(V\\) here refers to voltage, and not volume as previously defined. This contingency also holds true for Ohm’s law as defined below.↩︎\nWe don’t care about what happens at \\(t=0\\). Stop it.↩︎"
  },
  {
    "objectID": "ch3.html#preface",
    "href": "ch3.html#preface",
    "title": "3  Our Second Order of Business",
    "section": "Preface",
    "text": "Preface\nFirst order systems are honestly pretty boring. When we put in a step input, we just get a pure exponential. We won’t be able to get more interesting behavior, like oscillation, because that’s just mathematically impossible.1\nSecond order systems, on the other hand, can oscillate by themselves. Try to convince yourself of this mathematically just based on what oscillation is.\nMass-spring systems are pretty good models of everything in the world (as long as you use enough mass-spring systems). They’re really nice because having a good understanding of ONE mass-spring system provides us with the intuition for more complicated systems."
  },
  {
    "objectID": "ch3.html#mass-and-spring",
    "href": "ch3.html#mass-and-spring",
    "title": "3  Our Second Order of Business",
    "section": "3.1 Mass and Spring",
    "text": "3.1 Mass and Spring\nSay we have a mass-spring system where a mass \\(m\\) is attached to a wall with a spring \\(k\\) and a damper \\(b\\). Gravity isn’t “turned on”, so if you want to visualize the system, that mass is floating. The equation of motion for a positive displacement \\(q\\) is:2\n\\[m\\ddot{q} = -kq - b\\dot{q}\\]\nOr in its more familiar form:\n\\[m\\ddot{q} + b\\dot{q} + kq = 0\\]\nThis is the famed mass-spring equation. Say we have an input - a force \\(u\\) acting on the mass in the positive direction. Now our equation of motion is:\n\\[m\\ddot{q} + b\\dot{q} + kq = u\\]\nThis is a linear differential equation, so we’ll solve this by plugging in an educated guess. Let’s try \\(q(t) = Ae^{st}\\), because differentiating this function \\(n\\) times just multiplies it by \\(s^n\\).\nFirst, we’ll solve the homogeneous equation, or the case where \\(u=0\\).3\n\\[m\\ddot{q} + b\\dot{q} + kq = 0\\] \\[ms^2 Ae^{st} + bs Ae^{st} + kAe^{st} = 0\\] \\[ms^2 + bs + k = 0\\]\nThis is known as the characteristic (or auxiliary) equation. We can now use algebra to solve for the roots of the equation, or by proxy, the solution of the differential equation.\n\\[s_{1, 2} = \\frac{-b \\pm \\sqrt{b^2 - 4mk}}{2m}\\]\nThese are also called the poles of the system, but we’re getting ahead of ourselves. Let’s simplify further.\n\\[s_{1, 2} = \\frac{-b \\pm \\sqrt{b^2 - 4mk}}{2m} = -\\frac{b}{2m} \\pm \\sqrt{\\frac{b^2 - 4mk}{4m^2}} = -\\frac{b}{2m} \\pm \\sqrt{\\left(\\frac{b}{2m} \\right)^2 - \\frac{k}{m}}\\]\nWe define the natural frequency \\(\\omega_n = \\sqrt{\\frac{k}{m}}\\) and the damping ratio \\(\\zeta = \\frac{b}{2m\\omega_n}\\). Using these definitions, we can reorganize the mass-spring equation in terms of these variables.\n\\[m\\ddot{q} + b\\dot{q} + kq = 0 \\qquad \\to \\qquad \\ddot{q} + 2\\zeta\\omega_n \\dot{q} + \\omega_n^2 q = 0\\]\nAnd the poles of this equation are:\n\\[s_{1, 2} = -\\zeta \\omega_n \\pm \\omega_n \\sqrt{\\zeta^2 - 1}\\]"
  },
  {
    "objectID": "ch3.html#a-quick-dive-into-complex-analysis",
    "href": "ch3.html#a-quick-dive-into-complex-analysis",
    "title": "3  Our Second Order of Business",
    "section": "3.2 A Quick Dive into Complex Analysis",
    "text": "3.2 A Quick Dive into Complex Analysis\nComplex analysis is the study of functions of a complex variable \\(z\\), where \\(z\\) has a real component \\(a\\) and an imaginary component \\(b\\). Complex numbers show up all the time in this course, whenever anything oscillates, really (like mass-spring systems or pendulums).\nTo take our first plunge into complex analysis, we need to define the imaginary unit \\(i\\).4 For now, let’s define \\(i\\) as one of the two solutions to the quadratic equation \\(x^2 = -1\\). (The other is \\(-i\\), of course.) This is really special, because now we can describe the solutions of ALL polynomials5 as the sum of a real number \\(a\\) and another real number \\(b\\) multiplied by the imaginary unit \\(i\\).\nLet’s conjure up a graphical representation of these numbers using Cartesian coordinates, where we define one axis as “real” and the other as “imaginary”. We’ll call this the complex plane. An arbitrary point \\(z = a+ ib\\) is plotted below.\nWe can also interpret these numbers in the context of polar coordinates, where \\(\\theta\\) is the angle between the vector from the origin to \\(z\\) and the real axis, and \\(r\\) is the magnitude of the aforementioned vector. It’s not difficult to translate between Cartesian coordinates and polar coordinates, but I’ll dump the formulas here anyway.\n\\[a = r \\cos{\\theta} \\qquad b = r \\sin{\\theta} \\qquad r = \\sqrt{a^2 + b^2} \\qquad \\theta = \\arctan\\left({\\frac{b}{a}}\\right)\\]\nIt’d be criminal to not mention Euler’s formula, which posits that: 6\n\\[e^{i\\theta} = \\cos{\\theta} + i \\sin{\\theta}\\]\nA lot of the nuance of complex numbers is best understood by analyzing this complex exponential, especially because:\n\\[z = a+ib = r\\cos{\\theta} + ir \\sin{\\theta} = r (\\cos{\\theta} + i \\sin{\\theta}) = re^{i\\theta}\\]"
  },
  {
    "objectID": "ch3.html#damping",
    "href": "ch3.html#damping",
    "title": "3  Our Second Order of Business",
    "section": "3.3 Damping!",
    "text": "3.3 Damping!\nWhen \\(\\zeta = 0\\) (or the system is undamped), we have the poles \\(s_{1, 2} = \\pm i\\omega_n\\). This implies that our solution is a linear combination of sines and cosines, endlessly oscillating, forever and ever. (That’s kind of depressing to be honest.)\n\nWhat next? Euler guy.\nProf. Luchtenburg\n\n\\[x(t) = A_1 e^{i\\omega_n t} + A_2 e^{- i \\omega_n t} = A_1 (\\cos(\\omega_n t) + i \\sin(\\omega_n t)) + A_2 (\\cos(\\omega_n t) - i \\sin(\\omega_n t))\\] \\[= (A_1 + A_2) \\cos(\\omega_n t) + i(A_1 - A_2) \\sin(\\omega_n t) = C_1 \\cos(\\omega_n t) + C_2 \\sin(\\omega_n t)\\]\nThis reasoning carries over if we pick a damping ratio \\(\\zeta\\) between 0 and 1 (or the system is underdamped). The poles are:\n\\[s_{1, 2} = -\\zeta \\omega_n \\pm \\sqrt{\\omega_n^2 (\\zeta^2 - 1)} = -\\zeta \\omega_n \\pm i \\omega_n \\sqrt{1 - \\zeta^2} = \\sigma \\pm i \\omega_d\\]\nWe define the damped frequency \\(\\omega_d = \\omega_n \\sqrt{1-\\zeta^2}\\). (In practice, \\(\\omega_d \\approx \\omega_n\\), because \\(\\zeta \\ll 1\\).) Additionally, we define \\(\\sigma = \\zeta\\omega_n\\) (for some reason). After substituting these new variables in, our solution becomes:\n\\[x(t) = A_1 e^{(-\\sigma + i\\omega_d) t} + A_2 e^{(-\\sigma - i\\omega_d) t} = e^{-\\sigma t} (C_1 \\cos(\\omega_n t) + C_2 \\sin(\\omega_n t))\\]\nIn the lattermost form, it’s obvious that \\(\\sigma\\) in fact have a use other than bookkeeping; it defines the exponential envelope by which the oscillation decays. An envelope is a function that outlines how a function grows/decays (it’s the red dashed line in the figure below).\nNotably, the time constant \\(\\tau\\) of the envelope is equal to \\(1/\\sigma\\). Thus, we can eyeball the value of \\(\\sigma\\) based on how we’d find the time constant (the value \\(63\\%\\) less than the \\(y\\)-intercept of the envelope). \\[x(t) = e^{-\\sigma t} \\sin(\\omega_d t + \\varphi)\\]\nMost mechanical systems tend to have a very low damping ratio (\\(\\zeta \\simeq O(0.1)\\))7, and as mentioned before, a good rule of thumb is that \\(\\omega_n = \\omega_d\\).\nWhen we apply some initial conditions (like \\(q(0) = q_0\\) and \\(\\dot{q}(0) = v_0\\)), our solution becomes:\n\\[q(t) = e^{\\sigma t} \\left(q_0 \\cos(\\omega_d t) + \\frac{\\sigma q_0 + v_0}{\\omega_d} \\sin(\\omega_d t)\\right)\\]\nWhen \\(\\zeta = 1\\), or the system is critically damped, the poles are:\n\\[s_{1, 2} = -\\zeta \\omega_n\\]\nWe use a trick from differential equations to fake another linearly independent solution, just chuck on an extra \\(t\\).\n\\[q(t) = A_1 e^{-\\zeta \\omega_n t} + A_2 t e^{-\\zeta \\omega_n t}\\]\nThis doesn’t really happen in the real world, but it’s nice to cover all our bases. How about when \\(\\zeta &gt; 1\\)? We call this case overdamped, because our poles are:\n\\[s_{1, 2} = -\\zeta \\omega_n \\pm \\omega_n \\sqrt{\\zeta^2 - 1}\\]\nBoth poles are negative here! Our solution is:\n\\[q(t) = A_1 e^{s_1 t} + A_2 e^{s_2 t}\\]"
  },
  {
    "objectID": "ch3.html#pole-plots",
    "href": "ch3.html#pole-plots",
    "title": "3  Our Second Order of Business",
    "section": "3.4 Pole Plots",
    "text": "3.4 Pole Plots\nI’ve been emphasizing poles a lot in the last few pages, but why? What’s the importance of these seemingly arbitrary values? In fact, we can infer the dynamics of a system based on its poles.8\nTo analyze poles, we use a graphical tool called a pole plot, the plot of the roots of the characteristic equation on the complex plane. Let’s go down the list:\n\nWhen both poles are on the imaginary axis, the system is undamped.\nWhen both poles are off the real axis, the system oscillates. If they’re to the left of the imaginary axis, it’ll decay exponentially (underdamped), and if they’re to the right of the imaginary axis, it’ll grow exponentially.\nIf both poles are on the real axis to the left of the imaginary axis, it’s overdamped.\nRule of thumb: if there is ANY pole to the right of the imaginary axis, the response blows up.\n\nHere’s a nice chart from FPE. Complex conjugates are omitted for simplicity."
  },
  {
    "objectID": "ch3.html#leveraging-the-discriminant",
    "href": "ch3.html#leveraging-the-discriminant",
    "title": "3  Our Second Order of Business",
    "section": "3.5 Leveraging the Discriminant",
    "text": "3.5 Leveraging the Discriminant\nI’m going to stray off from Prof. Luchtenburg for a second because I think this is useful.\nSuppose we want to identify the dampedness of a system based on the equation of motion rather than solving for \\(\\zeta\\). We can do exactly this using the discriminant of the characteristic equation of the system. Let’s take a look at the canonical mass-spring system with a damper once again.\nThe equation of motion, assuming free motion, is: \\[m\\ddot{q} + b \\dot{q} + k q = 0\\]\nThe characteristic equation is derived after plugging in \\(q = e^{st}\\). \\[ms^2 + bs + k = 0\\]\nAs stated in the section on damping, there are three forms of the general solution if there is damping present: both poles are real and distinct (the system is overdamped), both poles are real and equal (the system is critically damped), or both poles are complex conjugates (the system is underdamped). You may recall from Algebra that the discriminant of a polynomial can reveal some properties of the roots without actually computing them. The discriminant of a quadratic is defined as follows: \\[\\text{Disc}(ax^2 + bx + c) = b^2-4ac\\]\nThis is the argument of the square root in the quadratic formula. If this expression is positive, the solutions to the quadratic are real and distinct. If this expression is 0, then there is only one real solution to the quadratic. If this expression is negative, the solutions to the quadratic are complex. So physically, finding the discriminant of the characteristic equation of the mass-spring system will tell us how damped it is. \\[\\text{Disc}(ms^2 + bs + k) = b^2-4mk\\]\n\\[\\begin{align*}\n    b^2 - 4mk &gt; 0 \\quad &\\to \\quad \\text{overdamped} \\\\\n    b^2 - 4mk = 0 \\quad &\\to \\quad \\text{critically damped} \\\\\n    b^2 - 4mk &lt; 0 \\quad &\\to \\quad \\text{underdamped}\n\\end{align*}\\]\nAnd of course, if \\(b=0\\), then the system is undamped."
  },
  {
    "objectID": "ch3.html#the-tank-revisited-inertia",
    "href": "ch3.html#the-tank-revisited-inertia",
    "title": "3  Our Second Order of Business",
    "section": "3.6 The Tank, Revisited (Inertia)",
    "text": "3.6 The Tank, Revisited (Inertia)\nLet’s revisit the tank from our study of first order systems. However, we’ll make one small change: the outflow pipe now has a defined length of \\(L_p\\).\nLet’s model the same way we’ve been doing thus far. First, a conservation law:\n\\[\\dot{V} = -Q\\]\nNext, “Ohm’s law”:\n\\[Q = \\frac{\\Delta P}{R} = \\frac{P - P_\\text{atm}}{R}\\]\nIf we isolate a piece of the pipe (with length \\(L_p\\)) as shown below, we can demystify this system a bit.\nAssuming the cross-sectional area of the pipe \\(A_p\\) is constant, the pressure force \\(F_p = A_p \\Delta P\\) accelerates the fluid between the two ends of this pipe. Additionally, there is friction \\(F_f = -QRA_p\\) on the liquid caused by the resistance of the pipe. By leveraging Newton’s second law of motion, we now have a relationship between the pressure difference \\(\\Delta P\\) and the velocity of the water \\(v\\).\n\\[m \\frac{dv}{dt} = F_p + F_f = A_p \\Delta P - Q R A_p\\]\nThe mass \\(m\\) of the fluid between the two ends of this pipe is equal to the product of the density of the fluid \\(\\rho\\) and the volume between the two ends \\(V_p\\). (Notably, the volume \\(V_p = A_p L_p\\).)\n\\[\\rho \\, V_p \\, \\frac{dv}{dt} = \\rho A_p L_p \\, \\frac{dv}{dt} = A_p \\Delta P - RQ A_p\\]\nBecause the product of the cross-sectional area \\(A_p\\) and the fluid velocity \\(v\\) is equal to the volumetric flow rate \\(Q\\), we can rewrite this equation as follows:\n\\[\\frac{\\rho L_p}{A_p} \\, \\frac{dQ}{dt} = \\Delta P - RQ\\]\nOk, we can shed some light on what we’re doing now. We define inductance (also referred to as liquid-flow inertance or inertia) as a term that describes the change in potential required for a unit rate of fluid flow. Inductance is the tendency of the fluid to move; it’s created by the inertia of water flowing through the pipe. The mathematical definition of inductance is as follows:\n\\[L = \\frac{\\rho L_p}{A_p}\\]\nNote that this definition of inductance is only valid for flow systems, but analogous concepts occur in other fields (like inductors from circuit analysis)! Fluid components that have an inductance are analogous to these inductors, or mechanical components with inertia.\nLet’s wrap up this example. When we plug in the definition of \\(L\\) into our equation, a simple first order system rears its head.9\n\\[L \\, \\frac{dQ}{dt} + RQ = \\Delta P\\]\nLet’s throw it into canonical form so we can see its time constant.\n\\[\\left(\\frac{L}{R}\\right) \\dot{Q} + Q = \\frac{\\Delta P}{R} \\qquad \\qquad \\tau = \\frac{L}{R}\\]\nTo summarize, we’ve added a new tool to our arsenal: conservation of momentum (or Newton’s second law).\n\\[\\Delta P = L \\dot{Q} + RQ\\] \\[\\dot{V} = -Q\\] \\[C \\Delta P = V\\]\nBy combining these three equations, we can use tools from our studies of mass-spring systems to analyze… well… any second order system.\n\\[L \\Delta \\ddot{P} + R \\Delta \\dot{P} + \\frac{1}{C} \\Delta P = 0 \\qquad \\to \\qquad \\Delta \\ddot{P} + \\left(\\frac{R}{L}\\right) \\Delta \\dot{P} + \\left(\\frac{1}{LC}\\right) \\Delta P = 0\\] \\[m \\ddot{q} + b \\dot{q} + k q = 0 \\qquad \\to \\qquad \\ddot{q} + \\left(\\frac{b}{m}\\right) \\dot{q} + \\left(\\frac{k}{m}\\right) q = 0\\]\nWe simply retrofit the definitions of the natural frequency \\(\\omega_n\\) and damping ratio \\(\\zeta\\) based on how we defined them for mass-spring systems to determine how the oscillations behave. Here’s a quick example using the flow system analogy we’ve been using thus far: \\[\\qquad \\ddot{q} + 2\\zeta\\omega_n \\dot{q} + \\omega_n^2 q = 0 \\quad \\longleftrightarrow \\quad  \\Delta \\ddot{P} + \\left(\\frac{R}{L}\\right) \\Delta \\dot{P} + \\left(\\frac{1}{LC}\\right) \\Delta P = 0\\]\n\\[\\begin{align*}\n    2 \\zeta \\omega_n = \\frac{R}{L} \\qquad &\\longrightarrow \\qquad \\zeta = \\frac{R}{2L \\omega_n} = \\frac{R\\sqrt{LC}}{2L} = \\frac{R}{2} \\sqrt{\\frac{C}{L}}\\\\\n    \\omega_n^2 = \\frac{1}{LC} \\qquad &\\longrightarrow \\qquad \\omega_n = \\frac{1}{\\sqrt{LC}} = \\frac{\\sqrt{LC}}{LC}\n\\end{align*}\\]"
  },
  {
    "objectID": "ch3.html#footnotes",
    "href": "ch3.html#footnotes",
    "title": "3  Our Second Order of Business",
    "section": "",
    "text": "Prove it!↩︎\nProf. Luchtenburg went off on a tangent about Hooke being a genius for realizing that spring motion is linear near the origin here. That was pretty funny.↩︎\nIf you’re curious why we do this, you can read up on it in a linear algebra textbook. Think it’s theorem 3.9 in Friedberg’s Linear Algebra.↩︎\nYou’ll see people, especially electrical engineers, use \\(j\\) instead, because \\(i\\) is commonly used for current. We’re better than them.↩︎\nRegardless if its coefficients are real or complex!↩︎\nYou can prove this using the Taylor series representation of \\(e^{x}\\). You should do it, it’s very rewarding↩︎\nRelated rates of growth from Ma111, or big-O notation if you’ve taken ECE264.↩︎\nThis is the crux of a lot we do in ME351. If any of you remember what an eigenvalue is from Ma110, that’ll come in handy in a bit.↩︎\nThe analog of this system in circuit analysis is called the RL circuit, which is often used as a passive filter.↩︎"
  },
  {
    "objectID": "ch4.html#preface",
    "href": "ch4.html#preface",
    "title": "4  An Engineering Student’s Butchering of Ma326",
    "section": "Preface",
    "text": "Preface\nThis chapter’s going to be a smorgasbord of mathematical concepts I think are foundational to understanding this course from a theoretical perspective. A decent chunk of it will be review from Ma110 and Ma240, but it doesn’t hurt to take a second look at these things (they keep coming back over and over). That being said, this chapter largely strays off from Prof. Luchtenburg’s curriculum, especially in the latter half of section 4.3.\nWhat I’ll try to do, instead of rehashing what you got out of Ma240, is reframe these concepts in a way that’s more applicable to this course (and ME351). I’ll also formalize a bunch of concepts from Ma326 that are really important to know for this class (and later on). But first, let’s formalize a few more definitions that will come in handy later on.\nA linear combination of elements of a set \\(x_1, x_2, ..., x_n\\), is given by:\n\\[a_1 x_1 + a_2 x_2 + ... + a_n x_n \\]\nwhere each \\(a_i\\) is a constant. In layman’s terms, a linear combination of variables is the sum of scaled versions of those variables, where the scaling factor is a scalar.\nA set of variables are linearly dependent if one of the variables can be expressed as a linear combination of the others. More formally, a set of variables \\(x_1, x_2, ..., x_n\\) is linearly dependent if there exist scalars \\(a_1, a_2, ... a_n\\) (not all zero), such that:\n\\[a_1 x_1 + a_2 x_2 + ... + a_n x_n = 0\\]\nOn the other hand, if no such scalars exist, the set of variables is said to be linearly independent."
  },
  {
    "objectID": "ch4.html#linearity-and-time-invariance",
    "href": "ch4.html#linearity-and-time-invariance",
    "title": "4  An Engineering Student’s Butchering of Ma326",
    "section": "4.1 Linearity and Time-Invariance",
    "text": "4.1 Linearity and Time-Invariance\nA is a mathematical model often used in control theory to describe the behavior of physical systems. It is characterized by two properties: linearity and time-invariance. I’ll describe these separately in the context of differential equations. A differential equation of the form:\n\\[a_n y^{(n)} (t) + a_{n-1} y^{(n-1)} + ... + a_1 \\dot{y}(t) + a_0 y(t) = f(t)\\]\nwhere \\(y^{(i)}\\) is the \\(i\\)th derivative of \\(y(t)\\), is called . (The relationship between \\(y(t)\\) and \\(t\\) is a linear mapping.) A system is linear if and only if it satisfies two properties: superposition and homogeneity:\n\nSuperposition - if \\(x_1 \\to y_1\\) and \\(x_2 \\to y_2\\), then \\(x_1 + x_2 \\to y_1 + y_2\\)\nHomogeneity - if \\(k\\) is a scalar and \\(x \\to y\\), then \\(kx \\to ky\\)\n\nIf \\(\\{a_i\\}_0^n\\), also called coefficients, are constants, the equation is also characterized as a differential equation. Physically, constant coefficients imply that the system behavior does not depend on time.\nWe can establish an equivalence between linear constant coefficient equations and linear time-invariant systems. Time-invariance is the principle that if we chug an input \\(t_0\\) into a system that outputs \\(y(t_0)\\), the input \\(t_0 + t_1\\) will result in an output of \\(y(t_0 + t_1)\\).1\nLet’s take a look at a few examples to make this more clear:\n\\[\\dot{y} + \\sin(t) y = 0\\]\nThis system is not LTI, because the coefficient of \\(y\\) is not constant. (More explicitly, it’s a function of \\(t\\), so as \\(t \\to \\infty\\), the behavior is affected.)\n\\[2 \\dot{y} + 3 y = 0\\]\nThis system is LTI, because the coefficients of each derivative of \\(y\\) are constant.\n\\[\\dot{y} + \\ln(y) = 0\\]\nThis system isn’t even linear, for obvious reasons.\nExamples of LTI systems include first-order passive filters, second order systems such as springs and masses, and many other linear systems in control theory and signal processing."
  },
  {
    "objectID": "ch4.html#matrices-at-lightspeed",
    "href": "ch4.html#matrices-at-lightspeed",
    "title": "4  An Engineering Student’s Butchering of Ma326",
    "section": "4.2 Matrices, at Lightspeed",
    "text": "4.2 Matrices, at Lightspeed\nI truly hope you know what a matrix is by now. If not, fasten your seatbelt.\nA matrix is a rectangular array of numbers, of the form:\n\\[\\textbf{A} = \\begin{bmatrix}\n    a_{11} & a_{12} & ... & a_{1n}\\\\ a_{21} & a_{22} & ... & a_{2n}\\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m1} & a_{m2} & ... & a_{mn}\n\\end{bmatrix}\\]\nwhere \\(a_{ij}\\) is the entry at row \\(i\\) and column \\(j\\). We say a matrix is of size \\(m \\times n\\), where \\(m\\) is the number of rows and \\(n\\) is the number of columns.\n\\[\\underbrace{\\begin{bmatrix}\n    1 & 2 \\\\ 3 & 4 \\\\ 5 & 6\n\\end{bmatrix}\n}_{3\\times 2}\\]\nMatrices are pretty neat. We can add numbers in the matrix elementwise and scale it by a scalar factor as follows:\n\\[\\begin{bmatrix}\n    a_1 & b_1 \\\\ c_1 & d_1\n\\end{bmatrix} + \\begin{bmatrix}\n    a_2 & b_2 \\\\ c_2 & d_2\n\\end{bmatrix} = \\begin{bmatrix}\n    a_1 + a_2 & b_1 + b_2 \\\\ c_1 + c_2 & d_1 + d_2\n\\end{bmatrix}\\]\n\\[ k \\begin{bmatrix}\n    a & b \\\\ c & d\n\\end{bmatrix} = \\begin{bmatrix}\n    ka & kb \\\\ kc & kd\n\\end{bmatrix}\\]\nThe zero matrix 0 is an \\(m\\times n\\) matrix with all entries 0. The zero matrix plays an important role in linear algebra, as it is the additive identity for matrices. This means that adding a zero matrix to any matrix does not change the matrix, much like adding zero to any number does not change its value.\nA square matrix is a matrix with the same number of rows and columns. Many concepts in linear algebra are designed with these in mind, such as determinants and eigenvalues.\nNext, we’ll tackle the Kronecker delta, which is is a useful and important symbol in mathematics, particularly in linear algebra and related fields. Its simple definition allows for the easy expression of many concepts and operations, making it a valuable tool for mathematicians and scientists. We define the Kronecker delta \\(\\delta_{ij}\\) as follows:\n\\[\\begin{equation*}\n    \\delta_{ij} = \\left\\{ \\begin{array}{ll}\n        1 \\quad i=j\\\\\n        0 \\quad i \\neq j\n    \\end{array} \\right.\n\\end{equation*}\\]\nFollowing from this, the identity matrix \\(\\textbf{I}_n\\) is defined as an \\(n\\times n\\) square matrix where \\((\\textbf{I}_n)_{ij} = \\delta_{ij}\\), i.e.,\n\\[\\textbf{I}_1 = 1, \\; \\textbf{I}_2 = \\begin{bmatrix}\n    1 & 0 \\\\ 0 & 1\n\\end{bmatrix}, \\; \\textbf{I}_3 = \\begin{bmatrix}\n    1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1\n\\end{bmatrix}, \\; ...\\]\nThe set of all matrices fixed at size \\(m \\times n\\) with scalar entries forms something we call a vector space. There’s a lot of nuance attached to that name; if you care about it, take Ma326. Here are a few properties for now. (Bolded quantities are matrices, \\(a, b,\\) and 1 are scalars.)\n\nMatrix addition is commutative, i.e., \\(\\textbf{X} + \\textbf{Y} = \\textbf{Y} + \\textbf{X}\\)\nMatrix addition is associative, i.e., \\((\\textbf{X} + \\textbf{Y}) + \\textbf{Z} = \\textbf{X} + (\\textbf{Y} + \\textbf{Z})\\)\nEach matrix has an additive identity, i.e., \\(\\textbf{X} + \\textbf{0} = \\textbf{X}\\)\nEach matrix has an additive inverse, i.e., \\(\\textbf{X} + \\textbf{Y} = \\textbf{0}\\)\nEach matrix has a scalar multiplicative identity, i.e., \\(1 (\\textbf{X}) = \\textbf{X}\\)\n\\((ab)\\textbf{X} = a(b\\textbf{X})\\)\n\\(a(\\textbf{X} + \\textbf{Y}) = a\\textbf{X} + a\\textbf{Y}\\)\n\\((a+b)\\textbf{X} = a\\textbf{X} + b\\textbf{X}\\)\n\nWe can multiply two matrices of sizes \\(m\\times n\\) and \\(n\\times p\\), respectively, to produce another matrix of size \\(m\\times p\\). The operation, dubbed matrix multiplication, should not be confused with the scalar multiplication used before. It’s defined as follows:\n\\[(\\textbf{AB})_{ij} = \\sum_{k=1}^n \\textbf{A}_{ik} \\textbf{B}_{kj}\\]\nFinding the product of two matrices may look intimidating based off that formula, but it’s actually not that difficult once you understand the basic steps. First, you need to make sure that the matrices are compatible for multiplication. To do this, we need to ensure that the number of columns in the first matrix is the same as the number of rows in the second matrix. If they’re not the same, you can’t multiply them.2\nOnce you’ve determined that the matrices are compatible, you can start multiplying. To find each element in the product matrix, you need to multiply the corresponding row in the first matrix by the corresponding column in the second matrix. Specifically, for each element in the product matrix, you will:\n\nTake the row of the first matrix that corresponds to that element.\nTake the column of the second matrix that corresponds to that element.\nMultiply each corresponding pair of elements in the row and column.\nAdd up all of the products you got in the last step.\n\nKeep doing this for every element in the product matrix until you’ve filled in all the entries. Here’s a brief example:\n\\[\\begin{bmatrix}\n    1 & 2 & 3 \\\\\n    4 & 5 & 6\n    \\end{bmatrix}\n    \\begin{bmatrix}\n    1 & 2 \\\\\n    3 & 4 \\\\\n    5 & 6\n    \\end{bmatrix}\n    =\n    \\begin{bmatrix}\n    1 \\cdot 1 + 2 \\cdot 3 + 3 \\cdot 5 & 1 \\cdot 2 + 2 \\cdot 4 + 3 \\cdot 6 \\\\\n    4 \\cdot 1 + 5 \\cdot 3 + 6 \\cdot 5 & 4 \\cdot 2 + 5 \\cdot 4 + 6 \\cdot 6\\end{bmatrix} = \\begin{bmatrix} 22 & 28 \\\\ 49 & 64 \\end{bmatrix}\\]\nMatrix products show up everywhere. They’re essential for fields like population modeling, network theory, signal processing, advanced dynamics, etc. Try to be as comfortable as possible with this operation before diving into the next chapter."
  },
  {
    "objectID": "ch4.html#transposition-and-symmetry",
    "href": "ch4.html#transposition-and-symmetry",
    "title": "4  An Engineering Student’s Butchering of Ma326",
    "section": "4.3 Transposition and Symmetry",
    "text": "4.3 Transposition and Symmetry\nThe transpose of an \\(m\\times n\\) matrix \\(\\textbf{A}\\) is the \\(n\\times m\\) matrix obtained by interchanging its rows and columns. It’s often denoted as \\(\\textbf{A}^\\text{T}\\) or \\(\\textbf{A}^\\text{t}\\).3 In other words, the rows of the original matrix become columns in the transposed matrix, and the columns become rows.\n\\[\\textbf{A} = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\\\ 5 & 6 \\end{bmatrix} \\qquad \\qquad \\textbf{A}^\\text{T} = \\begin{bmatrix} 1 & 3 & 5 \\\\ 2 & 4 & 6 \\end{bmatrix}\\]\nLet’s follow up with a few more properties that involve transposition. (Bolded quantities are matrices, \\(a, b\\) are scalars.)\n\n\\(\\left(\\textbf{X}^\\text{T}\\right)^\\text{T} = \\textbf{X}\\)\n\\((\\textbf{X}+\\textbf{Y})^\\text{T} = \\textbf{X}^\\text{T} + \\textbf{B}^\\text{T}\\)\n\\(a\\textbf{X}^\\text{T} = (a\\textbf{X})^\\text{T}\\)\n\\((\\textbf{X}\\textbf{Y})^\\text{T} = \\textbf{Y}^\\text{T} \\textbf{X}^\\text{T}\\)\n\nA symmetric matrix is a square matrix equal to its own transpose. (Another way to phrase this is: if \\(\\textbf{A}\\) is an \\(n\\times n\\) matrix, then \\(\\textbf{A}\\) is symmetric if and only if \\(\\textbf{A}^\\text{T} = \\textbf{A}\\).)\nTrivially, the sum of two symmetric matrices is symmetric, and a scalar multiple of a symmetric matrix is symmetric.\nThere’s other kinds of symmetry as well. For example, a skew-symmetric matrix is a square matrix equal to its negative. (Another way to phrase this is: if \\(\\textbf{A}\\) is an \\(n\\times n\\) matrix, then \\(\\textbf{A}\\) is skew-symmetric if and only if \\(\\textbf{A}^\\text{T} = -\\textbf{A}\\).) This turns out to be much more interesting than its vanilla counterpart in dynamics, especially when dealing with concepts like inertial tensors and angular momentum.\nAgain, trivially, the sum of two skew-symmetric matrices is symmetric, and a scalar multiple of a skew-symmetric matrix is symmetric. Additionally, you may realize that every entry on the diagonal of a skew-symmetric matrix must be equal to 0. (Otherwise, how would the definition work?)\nThis factoid turns out to be crucial if we focus on the 3-space case, there are only three independent entries of a skew-symmetric matrix. We can define a skew-symmetric operator for vectors in 3-space skew() as follows:4\n\\[\\text{skew}(\\boldsymbol{x}) = \\text{skew}(x_1, x_2, x_3) = \\begin{bmatrix} 0 & -x_1 & x_2 \\\\ x_1 & 0 & -x_3 \\\\ -x_2 & x_3 & 0\\end{bmatrix} \\]\nThis operator comes with a really cool property:\n\\[\\text{skew}(\\boldsymbol{x})^\\text{T} = -\\text{skew}(\\boldsymbol{x})\\]\nwhich comes in handy a lot in advanced dynamics. Additionally, we can make an alternative definition of the vector cross product.\n\\[\\boldsymbol{x} \\times \\boldsymbol{y} = \\text{skew}(\\boldsymbol{x}) \\boldsymbol{y}\\]\nProve it! It’s kind of fun."
  },
  {
    "objectID": "ch4.html#invert-it-determineit",
    "href": "ch4.html#invert-it-determineit",
    "title": "4  An Engineering Student’s Butchering of Ma326",
    "section": "4.4 Invert It! Determine…It!",
    "text": "4.4 Invert It! Determine…It!"
  },
  {
    "objectID": "ch4.html#footnotes",
    "href": "ch4.html#footnotes",
    "title": "4  An Engineering Student’s Butchering of Ma326",
    "section": "",
    "text": "An equivalent definition in signal processing is that a system is time-invariant if it commutes with a “delay”.↩︎\nThis is a really great gut check when you’re finishing up a long calculation. If that matrix multiplication at the end of the problem is impossible, something must be up.↩︎\nI prefer the former notation and will be using it henceforth.↩︎\nYeah, you’ll see awful notation everywhere for this thing. I’m going to use skew() because why not.↩︎"
  },
  {
    "objectID": "ch5.html#preface---time-domain-modeling",
    "href": "ch5.html#preface---time-domain-modeling",
    "title": "5  A Mishmash of Modeling Concepts",
    "section": "Preface - Time Domain Modeling",
    "text": "Preface - Time Domain Modeling\nWhen we begin to analyze more complicated systems, it becomes less and less feasible to solve them analytically. As a result, we resort to setting up a system of differential equations rather than concatenating them into one as we’ve done in past chapters.\nThe state-space representation of a system describes the system’s behavior over time in terms of a set of variables called states.1 The state variables represent the current conditions of the system, and their evolution over time is described by a set of first order differential equations called state equations.\nThe state-space representation is a very powerful tool for modeling and analyzing physical systems, providing valuable insights into their behavior and enabling the development of control algorithms covered in ME351.\nAn important thing to note is that the state-space representation of a system is not unique. In fact, an infinite number of representations exist for a physical system."
  },
  {
    "objectID": "ch5.html#the-state-space-approach",
    "href": "ch5.html#the-state-space-approach",
    "title": "5  A Mishmash of Modeling Concepts",
    "section": "5.1 The State-Space Approach",
    "text": "5.1 The State-Space Approach\nIn the most general case, a state-state representation can be represented as the following:\n\\[\\begin{equation*}\n    \\left\\{ \\begin{array}{ll}\n        \\underline{\\dot{x}} = \\underline{f}(\\underline{x}, \\underline{u}) \\\\\n        \\underline{y} = \\underline{h}(\\underline{x}, \\underline{u})\n    \\end{array} \\right.\n\\end{equation*}\\]\nThis might be a bit daunting at first, but it’s just a lot of fancy notation for a concept that’s pretty simple. \\(\\underline{x}\\) is the state, \\(\\underline{u}\\) is an input, and \\(\\underline{y}\\) is an output. Let’s drive this concept home with an example.\nSay we have a simple pendulum with length \\(L\\) and a point mass \\(m\\) at its end, as pictured below:\nFor this problem, the mass of the rod (and any potential friction in the hinge) is ignored. The equation of motion of the pendulum can be derived by summing moments about the point of contact between the pendulum and the fixed surface.2 Let’s call that point of contact \\(O\\) for future bookkeeping purposes.\n\\[\\sum{M_O} = J_O \\ddot{\\theta}\\]\nThe moment arm for the weight \\(mg\\) is the horizontal displacement \\(L \\sin(\\theta)\\), and \\(J_O = mL^2\\) is the mass moment of inertia of the point mass \\(m\\) about point \\(O\\). Let’s crunch some numbers.\n\\[-mgL \\sin(\\theta) = mL^2 \\ddot{\\theta}\\] \\[mL^2 \\ddot{\\theta} + mgL \\sin(\\theta) = 0\\] \\[\\ddot{\\theta} + \\frac{g}{L} \\sin(\\theta) = 0\\]\nNow let’s try putting this in state-space form. First, we select the state vector, which should adhere to the following points:\n\nPick state variables that include all the relevant information about the system you’re trying to model.\nThe number of dimensions in the state vector should match the number of degrees of freedom of the system.\nThe state vector should be minimal, meaning it should contain only the information necessary to describe the system, and not any redundant information. (Usually, the minimum number required is equal to the order of the differential equation that represents the system.)\nThe components of the state vector must be linearly independent.\n\nA good rule of thumb is that the state should correspond with the initial conditions provided. We define states \\(\\theta\\) (angle) and \\(\\omega = \\dot{\\theta}\\) (angular velocity), and start constructing our state equations.\n\\[\\underline{x} = \\begin{bmatrix}\n    \\theta \\\\\n    \\omega  \\end{bmatrix} \\qquad \\qquad \\underline{\\dot{x}} = \\begin{bmatrix}\n        \\dot{\\theta} \\\\\n        \\dot{\\omega}  \\end{bmatrix}\\] \\[\\underline{\\dot{x}} = \\underline{f} (\\underline{x}, \\underline{u})\\]\n\\[\\dot{\\underline{x}} = \\begin{bmatrix}\n    \\dot{\\theta} \\\\\n    \\dot{\\omega}  \\end{bmatrix} = \\begin{bmatrix}\n    \\omega \\\\\n    -\\frac{g}{L} \\sin(\\theta)\n\\end{bmatrix}\\]\nWe’ve turned a second order differential equation into two first order differential equations. Let’s move onto the second part of the representation: defining the output \\(y\\). We’re interested in the states’ behavior over time, so our output is…just the state vector \\(\\underline{x}\\).\n\\[\\underline{y} = \\underline{h}(\\underline{x}, \\underline{u}) = \\underline{x} = \\begin{bmatrix}\n    \\theta \\\\\n    \\omega  \\end{bmatrix}\\]\nThese two components make up the state-space representation of this pendulum system. Putting it in this form makes it easier to numerically solve using tools like Python or MATLAB.\nA nonlinear solution can be unappealing, though perfectly valid. By using the small-angle approximation \\(\\sin(\\theta) \\sim \\theta\\), we can refine this representation further.\n\\[\\ddot{\\theta} + \\frac{g}{L} \\sin(\\theta) \\sim \\ddot{\\theta} + \\frac{g}{L} \\theta = 0\\]\nOur system is now an LTI system. Linearity is very nice, because we can use matrix multiplication to make this representation pretty.\n\\[\\dot{\\underline{x}} = \\begin{bmatrix}\n    \\dot{\\theta} \\\\\n    \\dot{\\omega}  \\end{bmatrix} = \\begin{bmatrix}\n    \\omega \\\\\n    -\\frac{g}{L} \\theta\n\\end{bmatrix} = \\begin{bmatrix}\n    0 & 1\\\\\n    -\\frac{g}{L} & 0\n\\end{bmatrix} \\begin{bmatrix}\n    \\theta \\\\\n    \\omega  \\end{bmatrix}\\]\nLet’s move onto the output equation, which is (in my opinion) less interesting than the state equation. What are we interested in analyzing here? Say we’re interested in analyzing \\(\\theta\\) - or more succinctly, \\(y = \\theta\\).\n\\[\\underline{y} = \\begin{bmatrix}\n    \\theta \\\\\n    \\omega  \\end{bmatrix} = \\begin{bmatrix}\n        1 & 0\n    \\end{bmatrix} \\begin{bmatrix}\n        \\theta \\\\\n        \\omega  \\end{bmatrix}\\]\nOr, more interestingly, say we want to track both states over time (\\(\\theta\\) and \\(\\omega\\)). Our output is just the state, so we set \\(y=\\underline{x}\\). In these cases, the “coefficient” matrix is the \\(n\\times n\\) identity matrix \\(\\textbf{I}_n\\), where \\(n\\) is the number of components in the state vector.\n\\[\\underline{y} = \\begin{bmatrix}\n    \\theta \\\\\n    \\omega  \\end{bmatrix} = \\begin{bmatrix}\n        1 & 0\\\\\n        0 & 1\n    \\end{bmatrix} \\begin{bmatrix}\n        \\theta \\\\\n        \\omega  \\end{bmatrix} = \\textbf{I}_2 \\begin{bmatrix}\n            \\theta \\\\\n            \\omega  \\end{bmatrix}\\]\nWe’ll move on using this output equation. Let’s make this more complicated by saying the pendulum has an input applied torque \\(T\\), and the new equation of motion is:\n\\[\\ddot{\\theta} + \\frac{g}{L} \\theta = \\frac{T}{mL^2}\\]\nOur revised state-space representation would be:\n\\[\\dot{\\underline{x}} = \\begin{bmatrix}\n    \\dot{\\theta} \\\\\n    \\dot{\\omega}  \\end{bmatrix} = \\begin{bmatrix}\n    \\omega \\\\\n    -\\frac{g}{L} \\theta + \\frac{T}{mL^2}\n\\end{bmatrix} = \\begin{bmatrix}\n    0 & 1\\\\\n    -\\frac{g}{L} & 0\n\\end{bmatrix} \\begin{bmatrix}\n    \\theta \\\\\n    \\omega  \\end{bmatrix} + \\begin{bmatrix}\n        0 \\\\\n        \\frac{1}{mL^2}  \\end{bmatrix} T = \\begin{bmatrix}\n            0 & 1\\\\\n            -\\frac{g}{L} & 0\n        \\end{bmatrix} \\underline{x} + \\begin{bmatrix}\n                0 \\\\\n                \\frac{1}{mL^2}  \\end{bmatrix} u\\] \\[\\underline{y} = \\begin{bmatrix}\n    \\theta \\\\\n    \\omega  \\end{bmatrix} = \\begin{bmatrix}\n        1 & 0\\\\\n        0 & 1\n    \\end{bmatrix} \\begin{bmatrix}\n        \\theta \\\\\n        \\omega  \\end{bmatrix} + \\begin{bmatrix}\n            0 \\\\\n            0  \\end{bmatrix} T = \\begin{bmatrix}\n                1 & 0\\\\\n                0 & 1\n            \\end{bmatrix} \\underline{x} + \\begin{bmatrix}\n                    0 \\\\\n                    0  \\end{bmatrix} u\\]\nUsing this example, we now extract the general form of the state-space representation of a linear system. A linear system is represented in state space by the following equations:\n\\[\\underline{\\dot{x}} = \\textbf{A} \\underline{x} + \\textbf{B} \\underline{u}\\]\n\\[\\underline{y} = \\textbf{C} \\underline{x} + \\textbf{D} \\underline{u}\\]\nfor \\(t \\ge t_0\\), \\(\\underline{x}(t_0)\\), where:\n\n\\(\\underline{x}\\) is the state vector, of size \\(n \\times 1\\)\n\\(\\underline{y}\\) is the output vector, of size \\(q \\times 1\\)\n\\(\\underline{u}\\) is the input vector, of size \\(p \\times 1\\)\n\\(\\textbf{A}\\) is the system matrix, of size \\(n \\times n\\)\n\\(\\textbf{B}\\) is the input matrix, of size \\(n \\times p\\)\n\\(\\textbf{C}\\) is the output matrix, of size \\(q \\times n\\)\n\\(\\textbf{D}\\) is the feedforward matrix, of size \\(q \\times p\\)\n\nLet’s try another example, this time a translational mechanical system. Block 1 of mass \\(m\\) is attached to a fixed wall by dashpot with damping coefficient \\(b\\). Block 2, also of mass \\(m\\), is attached to block 1 by a spring of spring constant \\(k\\). Gravity is turned off.\nFirst, we write the equations of motion of the network. (Just draw a free body diagram around each mass and don’t fuck up your signs.)\n\nYou want a hint? Newton guy.\nProf. Luchtenburg\n\n\\[m \\ddot{q_1} + b \\dot{q_1} + k q_1 - k q_2 = 0\\] \\[-kq_1 + m \\ddot{q_2} + k q_2 = f(t)\\]\nThis is a system of two second order differential equations, so we’ll pick four states. We select our \\(q_1\\), \\(\\dot{q_1}\\), \\(q_2\\), and \\(\\dot{q_2}\\) to be our four state variables, because we’re analyzing the kinematic behavior of two masses obeying Newton’s second law (N2L is a second order differential equation, which requires two initial conditions, and since there’s two masses to analyze we have four).\nOur first two state equations are easy: just define the derivatives. We get the other two by rearranging the equations of motion and isolating \\(\\ddot{q_1}\\) and \\(\\ddot{q_2}\\).\n\\[\\dot{\\underline{x}} = \\begin{bmatrix}\n    \\dot{q_1} \\\\\n    \\ddot{q_1} \\\\\n    \\dot{q_2} \\\\\n    \\ddot{q_2}\n  \\end{bmatrix} = \\begin{bmatrix}\n    0 & 1 & 0 & 0\\\\\n    -\\frac{k}{m} & -\\frac{b}{m} & \\frac{k}{m} & 0 \\\\\n    0 & 0 & 0 & 1\\\\\n    \\frac{k}{m} & 0 & -\\frac{k}{m} & 0\n\\end{bmatrix} \\begin{bmatrix}\n    q_1 \\\\\n    \\dot{q_1} \\\\\n    q_2 \\\\\n    \\dot{q_2} \\end{bmatrix} + \\begin{bmatrix}\n        0 \\\\\n    0 \\\\\n    0 \\\\\n    \\frac{1}{m} \\end{bmatrix} f(t)\\]\nNow, we didn’t specify what output we wanted, but let’s say we want to analyze the velocity of the second mass, or \\(\\dot{q_2}\\). We’d do the following:\n\\[y = \\begin{bmatrix} 0 & 0 & 0 & 1\\end{bmatrix} \\begin{bmatrix}\n    q_1 \\\\\n    \\dot{q_1} \\\\\n    q_2 \\\\\n    \\dot{q_2} \\end{bmatrix} + \\begin{bmatrix} 0 \\end{bmatrix} f(t)\\]\nwhich is equivalent to the expression \\(y = \\dot{q_2}\\). Even though it seems more complicated to put it in this form, it provides us with a \\(\\textbf{C}\\) and \\(\\textbf{D}\\) matrix, which is invaluable when analyzing systems computationally.\nWhat makes this example more significant than the previous one is that there’s now two different “entities” to analyze.3 Rather than just analyzing multiple states (position, velocity) of a singular entity like we did with the pendulum, we’re now taking a look at the position and velocity of two masses. That’s kind of nifty, I think."
  },
  {
    "objectID": "ch5.html#the-unit-impulse",
    "href": "ch5.html#the-unit-impulse",
    "title": "5  A Mishmash of Modeling Concepts",
    "section": "5.2 The Unit Impulse",
    "text": "5.2 The Unit Impulse\nTHWACK!\nYou hear that? It’s the sound of Prof. Baglione smacking something with an impact hammer, a tool used to simultaneously excite something and measure the impact force at the same time.\nIt’s really common in mechanical (and electrical, ugh) scenarios to want to analyze a very large force over a very short period of time. Say we’re interested in modeling a batter’s hit, a car crash, or…I don’t know…whacking a mass-spring system with an impact hammer.\nConsider a model of a hammer strike, pictured as follows.\nThis strike is modeled as a rectangular “pulse”, where the rule is:\n\\[F(t) = \\begin{cases}\n    0 & \\text{if } t \\leq t_0 - \\epsilon \\\\\n    \\frac{F_0}{2\\epsilon} & \\text{if } t_0 - \\epsilon &lt; t &lt; t_0 + \\epsilon \\\\\n    0 & \\text{if } t \\ge t_0 + \\epsilon\n\\end{cases}\\]\nWhen integrated over time, \\(F(t)\\) yields the impulse over \\(F\\).\n\\[\\text{Imp} = \\int_{0^-}^{\\infty} F(t) \\, dt = \\int_{t_0 - \\epsilon}^{t_0 + \\epsilon} \\frac{F_0}{2\\epsilon} \\, dt = \\frac{F_0}{2\\epsilon} \\left((t_0 + \\epsilon)-(t_0 - \\epsilon)\\right) = F_0\\]\nThis trick of “ripping out the integrand” only works when \\(\\epsilon \\neq 0\\). Nevertheless, we investigate the case where \\(\\epsilon \\to 0\\).4\nAs \\(\\epsilon\\) gets smaller and smaller, the magnitude of force \\(\\frac{F_0}{2\\epsilon}\\) gets larger and larger. Nevertheless, the impulse remains equal to \\(F_0\\). We define the impulse function as a function \\(F(t)\\) with the following two properties:\n\\[F(t-t_0)=0, \\; \\; t\\neq t_0 \\qquad \\qquad \\int_{0^-}^\\infty F(t) \\, dt = F_0\\]\nWe call an impulse function where \\(F_0 = 1\\) the unit impulse function, also called the Dirac delta function, denoted \\(\\delta(t)\\).5 Let’s rewrite the above principles for the unit impulse.\n\\[\\delta(t-t_0)=0, \\; \\; t\\neq t_0 \\qquad \\qquad \\int_{0^-}^\\infty \\delta(t) \\, dt = 1\\]\nIt’s important to realize that the unit impulse function…well…isn’t a function. The idea of a “function” that is equal to 0 everywhere except \\(t=t_0\\), where it’s equal to \\(\\infty\\) is preposterous! Additionally, for this “function” to make sense, the integral would be equal to 0.\nWe don’t care. We defined it that way.6\nThere exists an alternative definition of the unit impulse used in signal processing (that will also end up useful later on in this course).\n\\[\\int_{0^-}^\\infty \\delta(t-t_0) f(t)\\, dt = f(t_0)\\]\nwhere \\(f\\) is a continuous function. This is called the sifting property of the unit impulse function. The unit impulse function acts as a sampler; the juicy part of \\(\\delta(t-t_0)\\) is located at \\(t=t_0\\), so integrating the product of the impulse \\(\\delta(t-t_0)\\) and a continuous function \\(f(t)\\) yields \\(f(t_0)\\)."
  },
  {
    "objectID": "ch5.html#preface---frequency-domain-prerequisites",
    "href": "ch5.html#preface---frequency-domain-prerequisites",
    "title": "5  A Mishmash of Modeling Concepts",
    "section": "Preface - Frequency Domain Prerequisites",
    "text": "Preface - Frequency Domain Prerequisites\nWhile using the state-space representation of a system can be advantageous in situations where we have multiple inputs and multiple outputs, sometimes the linear algebra just gets too unwieldy, especially if you don’t have Python or MATLAB sitting in front of you. (This isn’t to say that transfer functions aren’t easily implementable in Python or MATLAB, though.)\nIn lieu of modeling in the time domain, we can use transfer functions to mathematically model systems in the frequency domain. This ends up being really useful in ME351 when we talk about how to control physical systems rather than just analyzing them. Transfer functions are also much easier to translate into graphical interpretations of systems, like Bode plots."
  },
  {
    "objectID": "ch5.html#the-laplace-transform",
    "href": "ch5.html#the-laplace-transform",
    "title": "5  A Mishmash of Modeling Concepts",
    "section": "5.3 The Laplace Transform",
    "text": "5.3 The Laplace Transform\nYou’ve likely brushed upon Laplace transforms in Ma240, so I’ll try to reintroduce them…err…less formally.\nThe Laplace transform is an essential tool for analyzing and designing control systems, making them a vital topic to cover in preparation for ME351. By learning about Laplace transforms, we can develop a deep understanding of the behavior of dynamic systems and how to control them.\nLaplace transforms allow us to simplify differential equations that describe the behavior of a system in the time-domain, into simpler algebraic equations in the \\(s\\)-domain. These equations can be easily analyzed to determine important system characteristics such as stability, steady-state error, and transient response.\nFurthermore, understanding Laplace transforms is crucial for designing controllers that can effectively control the behavior of a system. For example, by using Laplace transforms to analyze a system’s frequency response, engineers can design controllers that attenuate unwanted frequencies, leading to more desirable system performance.\nLet’s cut to the chase. The (one-sided) Laplace transform of a function \\(f(t)\\) is a new function \\(F(s)\\), \\(s \\in \\mathbb{C}\\), defined by:7 \\[ \\mathcal{L} \\{ f(t) \\} = F(s) = \\int_{0^-} ^\\infty e^{-st} f(t) dt \\]\nAs the Laplace transform is an integral transform, we know that it is linear. Thus, taking the Laplace transform of a linear combination of functions yields a linear combination of the Laplace transforms of the functions:\n\\[\\mathcal{L} \\{ \\alpha f(t) + \\beta g(t) \\} = \\mathcal{L} \\{ \\alpha f(t) \\} + \\mathcal{L} \\{ \\beta g(t) \\} = \\alpha \\mathcal{L} \\{ f(t) \\} + \\beta \\mathcal{L} \\{ g(t) \\} = \\alpha F(s) + \\beta G(s)\\]\nwhere \\(\\alpha, \\,\\beta\\) are constants. Here are a few common ones (easily verifiable with the integral definition).\n\\[\\mathcal{L} \\{ \\delta(t) \\} = 1\\] \\[\\mathcal{L} \\{ 1 \\} = \\frac{1}{s}\\] \\[\\mathcal{L} \\{ e^{at} \\} = \\frac{1}{s-a}\\]\nConfirm them yourself! (Or find a table of Laplace transforms, I don’t know…)\nOur objective is to use the Laplace transform to model physical systems. Thus, it is imperative that we find a way to take the Laplace transform of a derivative. Provided \\(f\\) and its derivatives are continuous from \\(0 \\le t &lt; \\infty\\), and are of exponential order,8 we do so as follows:\n\\[\\mathcal{L} \\left \\{\\frac{df(t)}{dt} \\right \\} = \\int_{0^-} ^\\infty e^{-st} \\frac{df(t)}{dt} dt = \\left[ e^{-st} f(t) \\right]_{0^-}^{\\infty} - \\int_{0^-} ^\\infty -s e^{-st} f(t) dt = -f(0) + sF(s)\\]\nor:\n\\[\\mathcal{L} \\left \\{ \\frac{df(t)}{dt} \\right \\} = sF(s) - f(0)\\]\nBy recursion, it is apparent that the Laplace transform of a second derivative is:\n\\[\\mathcal{L} \\left \\{\\frac{d^2f(t)}{dt^2} \\right \\} = sF'(s) - f'(0)= s(sF(s) - f(0)) - f'(0) = s^2 F(s) - sf(0) - f'(0)\\]\nand an \\(n\\)th derivative is:\n\\[\\mathcal{L} \\left \\{\\frac{d^n f(t)}{dt^n} \\right \\} = s^n F(s) - s^{n-1} f(0) - s^{n-2} f'(0) - ...- s f^{(n-2)}(0) - f^{(n-1)} (0)\\]\nIn the case that all initial conditions are zero, it’s valid to write:\n\\[\\mathcal{L} \\left\\{\\frac{d^n f(t)}{dt^n}\\right\\} = s^n F(s)\\]\nThis will be handy very soon.\nFinally, we’ll introduce the notion of the inverse Laplace transform, which transforms an expression in the \\(s\\)-domain back into the time domain.9 More concisely:\n\\[\\mathcal{L}^{-1} \\left\\{F(s)\\right\\} = f(t)\\]\nThe inverse Laplace transform is also a linear transformation. Notably, it’s not unique; there exist distinct \\(f\\) and \\(g\\) such that \\(\\mathcal{L} \\left\\{f \\right\\} = \\mathcal{L} \\left\\{g \\right\\}\\).\nUsing the technology we’ve formalized10 thus far, we can use the Laplace transform to solve initial value problems. Say we wanted to solve the IVP:\n\\[\\ddot{y} - 4\\dot{y} + 3 y = e^{2t}\\]\nwhere \\(y\\) is a function of \\(t\\), and \\(y(0) = \\dot{y}(0) = 0\\). First, we transform the whole equation into the \\(s\\)-domain.\n\\[s^2 Y - 4 sY + 3 Y = \\frac{1}{s-2}\\]\nSince our objective is to solve for \\(y(t)\\), it’s wise to isolate \\(Y(s)\\) on one side, so when we take the inverse Laplace transform, we immediately have an explicit formula \\(y\\).\n\\[Y (s^2 - 4 s + 3) = \\frac{1}{s-2}\\] \\[Y = \\frac{1}{(s-2)(s^2 - 4 s + 3)}\\]\nWe then find the partial fraction decomposition of this rational function, so that transforming back to the time domain is easier. 11\n\\[Y = -\\left(\\frac{1}{s-2} \\right) + \\frac{1}{2}\\left(\\frac{1}{s-1} \\right) + \\frac{1}{2}\\left(\\frac{1}{s-3}\\right)\\]\nAnd finally, we transform back.\n\\[y = -e^{2t} + \\frac{1}{2} e^{t} + \\frac{1}{2} e^{3t}\\]\nwhich matches whatever we’d get if we tried using a time domain method like the method of undetermined coefficients. Of course, we did a problem with zero initial conditions, but rest assured, if your goal is just to solve differential equations, we can consider cases with nonzero initial conditions as well."
  },
  {
    "objectID": "ch5.html#its-convoluted",
    "href": "ch5.html#its-convoluted",
    "title": "5  A Mishmash of Modeling Concepts",
    "section": "5.4 It’s Convoluted!",
    "text": "5.4 It’s Convoluted!\nBut what if we wanted to find the Laplace transform of an integral?\nConvolution is an operation that generates a function from two other piecewise continuous functions. We define the convolution \\(f \\ast g\\) of functions \\(f(t)\\) and \\(g(t)\\) as follows:\n\\[f(t) \\ast g(t) = \\int_0^t f(\\tau) g(t-\\tau) \\, d\\tau = \\int_0^t f(t-\\tau) g(\\tau) \\, d\\tau\\]\nSo what makes this operation special? The Laplace transform of the convolution \\(f(t) \\ast g(t)\\) is equal to the product of the Laplace transform of \\(f(t)\\) and \\(g(t)\\).\n\\[\\mathcal{L} \\left\\{f\\ast g \\right\\} = \\mathcal{L} \\left\\{f(t) \\right\\} \\mathcal{L} \\left\\{g(t) \\right\\} = F(s) G(s)\\]\nOr alternatively:\n\\[\\mathcal{L}^{-1} \\left\\{F(s) G(s) \\right\\} = f \\ast g\\]\nSo in the case that \\(g(t) = 1\\), the Laplace transform of the integral of \\(f(t)\\) is:\n\\[\\mathcal{L} \\left\\{\\int_0^t f(\\tau) d\\tau \\right\\} = \\frac{F(s)}{s}\\]"
  },
  {
    "objectID": "ch5.html#transfer-functions-and-block-diagrams",
    "href": "ch5.html#transfer-functions-and-block-diagrams",
    "title": "5  A Mishmash of Modeling Concepts",
    "section": "5.5 Transfer Functions and Block Diagrams",
    "text": "5.5 Transfer Functions and Block Diagrams\nWhen possible, we try to think of all systems as black boxes with an input and an output. We’ve covered how to represent a system in the time domain using the state-space representation. Let’s try something else.\nTransfer functions are often preferred over state space representations in certain situations because they are simple and easy to work with, especially for linear systems with a single input and a single output. They can be easily manipulated using some algebra and can be used to compute a system’s response to various input signals.\nTransfer functions are also very useful for frequency-domain analysis, such as calculating the system’s frequency response or designing filters to tweak the system’s frequency characteristics.\nMathematically, a transfer function is the ratio of the Laplace transform of the output of a system \\(Y(s)\\) to the Laplace transform of its input \\(U(s)\\), with all initial conditions assumed to be zero. The transfer function is typically denoted as \\(H(s)\\), where:\n\\[H(s) = \\frac{Y(s)}{U(s)}\\]\nThat’s all there is to it. Let’s try a variation of the system we tackled before.\n\\[\\ddot{y} - 4 \\dot{y} + 3y = u\\]\nSo instead of that exponential expression on the right side of the equation, we now have an arbitrary input \\(u(t)\\). Because we’re trying to find the transfer function, we assume zero initial conditions and take the Laplace transform of everything.\n\\[s^2 Y - 4 s Y + 3Y = U\\]\nThen, we find \\(H\\).\n\\[H = \\frac{Y}{U} = \\frac{1}{s^2 - 4s + 3}\\]\nUsing this transfer function, we can find the system response to any input we want. Say we’re interested in the response to a step input \\(u_s(t)\\). We can retrofit the definition of a transfer function to solve for the system response.\n\\[Y = H U\\]\nIn this scenario, \\(U\\) is the Laplace transform of \\(u_s(t)\\), or \\(\\frac{1}{s}\\).\n\\[Y = \\frac{1}{s^3 - 4s^2 + 3s}\\]\nwhich is left to complete as an exercise to the reader.12\nAh, one more thing! The roots of the numerator of the transfer function are called the \\(zeroes\\) of the system, and the roots of the denominator of the transfer function are called the \\(poles\\). These definitions are consistent with the definitions we established earlier in the course.\nThis seems like as good a time as any to introduce the concept of a block diagram, or a visual representation of a system, using blocks and arrows to break down components. We literally represent components as black boxes, without regard for whatever’s going on inside. All that matters is what comes in and what goes out. Seems perfect for a transfer function.\nHere’s a block diagram. \\(U\\) is our input signal, \\(Y\\) is the output signal, and \\(H\\) is the transfer function representation of the system. When a signal enters a system in a block diagram, the output signal will be the product of the signal and the system’s transfer function.\nWe can use additional tools of block diagram algebra to simplify and manipulate these diagrams, which ends up being vital when we start introducing feedback control into the mix."
  },
  {
    "objectID": "ch5.html#electrical-networks-and-impedance",
    "href": "ch5.html#electrical-networks-and-impedance",
    "title": "5  A Mishmash of Modeling Concepts",
    "section": "5.6 Electrical Networks and Impedance",
    "text": "5.6 Electrical Networks and Impedance\nIn ESC221, you may have covered the series RLC circuit, pictured as follows:\nwhere the source voltage \\(V_s\\) is the input of the system and the voltage across the capacitor \\(V_c\\) is the output. The governing equation of this system is a second order differential equation, but using transfer functions, we can turn this differential equation into an algebraic one.\nThis is especially advantageous when conducting an alternating current (AC) analysis of the network, when \\(V_s\\) could be a sinusoidal function. However, the formulation described in this course is applicable to any input signal.\nThe impedance \\(Z\\) of a two-terminal passive component like a resistor, capacitor, or inductor, is defined as the ratio of the Laplace transform of the voltage \\(\\tilde{V}\\) to the Laplace transform of the current \\(\\tilde{I}\\).\nOhm’s law states that \\(V = IR\\). When we take the Laplace transform of the expression, we get:\n\\[\\tilde{V} = \\tilde{I} R\\]\nThus, the impedance of a resistor is:\n\\[Z_R = \\frac{\\tilde{V}}{\\tilde{I}} = R\\]\nThat was…anticlimactic. Let’s try a capacitor next. The capacitive relationship states that \\(q = \\int I \\, dt = CV\\). When we take the Laplace transform of the expression, we get:\n\\[\\frac{1}{s} \\tilde{I} = C\\tilde{V}\\]\nThus, the impedance of a capacitor is:\n\\[Z_C = \\frac{\\tilde{V}}{\\tilde{I}} = \\frac{1}{sC}\\]\nThat’s more interesting. Finally, the inductive relationship states that \\(V = L\\frac{dI}{dt}\\). Again, Laplace transform:\n\\[\\tilde{V} = s L\\tilde{I}\\]\nand the impedance of an inductor is:\n\\[Z_L = \\frac{\\tilde{V}}{\\tilde{I}} = sL\\]\nHere’s a bit more context - think of impedance as the frequency domain “value” of a passive component. Complex resistance, if you will. Resistance is real, so there’s no reason impedance is different in the Laplace’d analog of Ohm’s law.\nRelatedly, for a direct current (DC) circuit, \\(s=0\\).\nLet’s take a look at the circuit again. The governing equation, found using Kirchhoff’s voltage law, is:\n\\[V_s - RI - L \\frac{dI}{dt} - V_c = 0\\]\nUsing these newfound impedances, we can immediately convert this system to a transfer function. Let’s Laplace the shit out of this thing. (Keep in mind that a transfer function is output over input.)\n\\[\\tilde{V_s} - \\tilde{I} (Z_R + Z_L + Z_C) = 0\\] \\[\\tilde{V_s} - \\tilde{I} (R + sL + \\frac{1}{sC}) = 0\\] \\[U = \\tilde{V_s} = \\frac{\\tilde{I}}{R + sL + \\frac{1}{sC}}\\qquad \\qquad Y = \\tilde{V_c} = \\frac{\\tilde{I}}{sC}\\] \\[\\frac{Y}{U} = \\frac{\\frac{\\tilde{I}}{sC}}{\\frac{\\tilde{I}}{R + sL + \\frac{1}{sC}}} = \\frac{s^2 CL + sCR + 1}{s^2 C^2}\\]\nWe can expand this idea to more than just passive components.13 Impedance is a reliable method for thinking about mechanical systems as well (such as mass-spring systems, systems involving gears, motors, etc.)\nThe pigeonhole here is that these systems are modeled as linear. The frequency domain does not translate well when we study nonlinear systems; instead, we tend to use more qualitative methods such as drawing phase portraits or bifurcation analysis."
  },
  {
    "objectID": "ch5.html#intermezzo---discretization",
    "href": "ch5.html#intermezzo---discretization",
    "title": "5  A Mishmash of Modeling Concepts",
    "section": "Intermezzo - Discretization",
    "text": "Intermezzo - Discretization\nLet’s take a look at a first order continuous system.\n\\[\\tau \\dot{y} + y = Ku\\]\nWe can discretize this system by using finite differences in lieu of derivatives. At time \\(t_k\\), we can approximate the derivative \\(\\dot{y}(t_k)\\) as follows:\n\\[\\dot{y}(t_k) \\approx \\frac{y(t_k) - y(t_{k-1})}{t_k - t_{k-1}}\\]\nPlugging in, we get:\n\\[\\tau \\frac{y(t_k) - y(t_{k-1})}{t_k - t_{k-1}} + y(t_{k-1}) = Ku(t_{k-1})\\]\nLet’s define \\(\\Delta t = t_k - t_{k-1}\\) and \\(\\alpha = \\frac{\\tau}{\\Delta t}\\) With a bit more algebra, we find that:\n\\[y(t_k) = \\frac{\\alpha - 1}{\\alpha} y(t_{k-1}) + \\frac{K}{\\alpha} u(t_{k-1})\\]\nOne more simplification: \\(\\beta = \\alpha^{-1}\\):\n\\[y(t_k) = (1-\\beta) y(t_{k-1}) + K \\beta u(t_{k-1})\\]\nDiscretization makes it much easier to use computational tools like MATLAB and Python to manipulate a signal without preexisting toolboxes."
  },
  {
    "objectID": "ch5.html#impulse-response",
    "href": "ch5.html#impulse-response",
    "title": "5  A Mishmash of Modeling Concepts",
    "section": "5.7 Impulse Response",
    "text": "5.7 Impulse Response\nNow that we’ve developed all this new technology, let’s draw some conclusions.\nFirst, let’s circle back to our discussion of the unit impulse. We define the impulse response \\(h(t)\\) as a function that describes the behavior of an LTI system when it’s stimulated with a unit impulse. The impulse response is the output of the system resulting from this very short, narrow input signal.\nSay we smack a damped mass-spring system with an impact hammer, exciting the mass with a force we’ll model as the unit impulse \\(\\delta(t)\\).\nThe equation of motion of this system is:\n\\[m\\ddot{x} + b \\dot{x} + kx = \\delta(t) \\qquad \\qquad \\text{or} \\qquad \\qquad \\ddot{x} + 2\\zeta \\omega_n \\dot{x} + \\omega_n^2 x = \\frac{1}{m} \\delta(t)\\]\nThat’s extremely daunting to solve, but we’ll use a nifty trick. We separate the equation of motion into two…“stages” - during the hammer thwack and after the hammer thwack. Assume the mass is at rest before we whack it.\nFor the hammer thwack itself, we integrate the equation of motion twice successively from \\(0\\) to time \\(t\\), where \\(t\\) is immediately after the smack:\n\\[\\int_{0^-}^t \\left(m \\ddot{x} + b \\dot{x} + kx = \\delta(\\tau) \\right) \\, d\\tau\\] \\[m \\dot{x} + bx + \\int_{0^-}^t kx \\, d\\tau = 1 \\qquad \\qquad \\longleftrightarrow \\qquad \\qquad m \\dot{x} = 1 - bx - \\int_{0^-}^t kx \\, d\\tau\\]\n\\[\\int_{0^-}^t \\left(\\int_{0^-}^t \\left(m \\ddot{x} + b \\dot{x} + kx = \\delta(\\tau) \\right) \\, d\\tau \\right) \\,d\\tau\\]\n\\[m x + \\int_{0^-}^t bx \\, d\\tau + \\int_{0^-}^t 1 - \\left(\\int_{0^-}^t kx \\, d\\tau \\right) \\, d\\tau = 0 \\qquad \\qquad \\longleftrightarrow \\qquad \\qquad m x = \\int_{0^-}^t 1 - bx - \\left(\\int_{0^-}^t kx \\, d\\tau \\right) \\, d\\tau\\]\nEvaluating these integrals at \\(t=0^+\\) yields the following two “initial conditions”: \\[x(0^+) = 0 \\qquad \\qquad \\dot{x}(0^+) = \\frac{1}{m}\\]\nSince after the hammer crack there is no force exciting the system, solving the homogeneous version of the equation of motion with these initial conditions will yield the impulse response.\n\\[m\\ddot{x} + b\\dot{x} + kx = 0 , \\; x(0^+) = 0 , \\;\\dot{x}(0^+) = \\frac{1}{m}\\] \\[x(t) = \\frac{1}{m \\omega_d} e^{-\\zeta \\omega_n t} \\sin(\\omega_d t) = h(t)\\]\nYou’ll get much more familiar with the concept of mechanical impulse in ME301.\nWe can calculate the response of a system to an arbitrary force of varying magnitude using the impulse response. To calculate the response of a structure to an external force, we use the concept of superposition, which involves breaking down the force into small parts and adding up the response to each part to get the response.\nFor example, if we have a force that varies over time, we can divide it into small time intervals of length \\(\\Delta t\\), and at each interval \\(t_k\\), we can calculate the response of the system to an impulse of force \\(\\Delta F_k = F(t_k)\\Delta t\\).\nTo do this, we use the impulse response function \\(h(t)\\), which represents the response of the system to a unit impulse of force applied at time \\(t=0\\). Then, the response of the system to the impulse of force \\(\\Delta F_k\\) applied at time \\(t_k\\) is given by \\(h(t-t_k)\\Delta F_k\\), where \\(h(t-t_k)\\) is the impulse response function shifted in time by \\(t_k\\).\nThus, the response of the system to the external force \\(F(t)\\) is given by the sum of the responses to all the impulses:\n\\[y(t) = \\sum_{k=1}^n \\Delta F_k h(t-t_k) = \\sum_{k=1}^n  F(t_k) h(t-t_k)\\Delta t\\]\nBy using smaller and smaller time intervals \\(\\Delta t\\), we can make this sum approach an integral:\n\\[y(t) = \\int_0^t  F(\\tau) h(t-\\tau) \\, d\\tau\\]\nwhich you may recognize as the convolution integral. While we used a mechanical framework to develop intuition for this concept, we can generalize further by saying that if you have the impulse response \\(h(t)\\) of the system, you can determine the response to an arbitrary input \\(u(t)\\) as follows:\n\\[y(t) = \\int_0^t u(\\tau) h(t-\\tau) \\, d\\tau\\]\nLet’s close out with one more thought. What if we have an input signal \\(U(s) = 1\\)? Then the output signal is just equal to the transfer function \\(H(s)\\). Thus, it’s valid to say that the impulse response of a system is equivalent to the inverse Laplace transform of the transfer function.14\nWe’ve established that we have two main representations of a linear system: the state-space representation and a transfer function. What if we want to convert between them?\nWell, it’s pretty easy in Python/MATLAB - just use a command. What’s\nIt’s possible to come up with infinitely many state-space representations of a system, but the transfer function of a system is unique."
  },
  {
    "objectID": "ch5.html#footnotes",
    "href": "ch5.html#footnotes",
    "title": "5  A Mishmash of Modeling Concepts",
    "section": "",
    "text": "The state space can be described as a Euclidean space where each state corresponds with an axis.↩︎\nAlternatively, you could sum forces in the parallel and perpendicular directions of motion to yield an equivalent result.↩︎\nYou could try to put the two tanks problem from HW1 in state-space form for extra practice.↩︎\nFigure from Zill, et al. (8)↩︎\nNot to be confused with the Kronecker delta!↩︎\nThe less dismissive answer is that the unit impulse function is an example of something we call a generalized function. Go take a functional analysis course if you want to pursue this further.↩︎\nThe two-sided Laplace transform instead has integral limits of \\(-\\infty\\) and \\(\\infty\\), but for causal signal inputs, the one-sided Laplace transform is equivalent. (A causal signal is a signal that is 0 for all \\(t&lt;0\\).)↩︎\nA function \\(f(t)\\) is said to be of exponential order if there exist positive constants \\(a\\) and \\(b\\) such that \\(|f(t)| \\le ae^{bt}\\) for all \\(t\\ge 0\\).↩︎\nIt might seem peculiar that I’m abstaining from providing a formula to directly calculate the inverse Laplace transform. You can look up Mellin’s inverse formula for additional hardship, but rest assured that it’s WAY more convenient to think of the inverse Laplace transform as just that - an inverse Laplace transform, instead of as its own distinct transform.↩︎\nMan, I said I was going to do this less formally!↩︎\nIf you’re not that comfortable with partial fraction decomposition, it might be a good idea to look up the Heaviside cover-up method. Thank me later.↩︎\nI’m too lazy to take the inverse Laplace transform of this. It’s not difficult though, knock yourself out.↩︎\nIn the electrical networks world, we can translate operational amplifiers (op amps) into impedances as well. Absolutely terrifying.↩︎\nThis might be more apparent if you think about this outside the Laplace domain, where \\(y(t) = \\delta(t)\\).↩︎"
  },
  {
    "objectID": "ch6.html#preface",
    "href": "ch6.html#preface",
    "title": "6  Frequency Response",
    "section": "Preface",
    "text": "Preface\nJust as the impulse response characterizes all systems in the time domain, the frequency response characterizes all systems in the frequency domain. The frequency response is a linear system’s steady-state response to sinusoidal inputs.\nMore broadly, the frequency response describes how a system responds to different frequencies of input signals. Understanding the frequency response is crucial for designing and analyzing systems like filters and amplifiers. It also plays a critical role in understanding the behavior of natural systems such as the human ear, which responds differently to different frequencies of sound waves."
  },
  {
    "objectID": "ch6.html#that-hertz",
    "href": "ch6.html#that-hertz",
    "title": "6  Frequency Response",
    "section": "6.1 That Hertz!",
    "text": "6.1 That Hertz!\nSo what exactly makes sinusoidal inputs so interesting?\nWell, plugging a sinusoidal input into an LTI system yields a sinusoidal response of the same frequency (in the steady-state). However, the response may differ in amplitude and phase.\nAs such, it’s common to use the phasor representation of a sinusoid for frequency response techniques, where the magnitude of the complex number is the amplitude of the wave, and the angle of the complex number is the phase. Say our input is \\(u(t) = A \\sin(\\omega t)\\). We can express this in terms of complex exponentials as follows:\n\\[u(t) = A \\sin(\\omega t) = \\frac{A}{2i} \\left(e^{i\\omega t} - e^{-i \\omega t} \\right)\\]\nUsing the convolution integral, let’s solve for a potential \\(y(t)\\).\n\\[\\begin{align*}\ny(t) &= \\int_{0^-}^t h(\\tau) u(t-\\tau) \\, d\\tau \\\\\n&= \\frac{A}{2i} \\int_{0^-}^t h(\\tau) \\left(e^{i\\omega (t - \\tau)} - e^{-i \\omega (t - \\tau)} \\right) \\, d\\tau = \\frac{A}{2i} \\int_{0^-}^t h(\\tau) \\left(e^{i\\omega t} e^{-i\\omega \\tau} - e^{-i\\omega t} e^{i\\omega \\tau} \\right) \\, d\\tau \\\\\n&= \\frac{A}{2i} \\int_{0^-}^t h(\\tau) \\left(e^{i\\omega t} e^{-i\\omega \\tau} \\right) \\, d\\tau - \\frac{A}{2i} \\int_{0^-}^t h(\\tau) \\left(e^{-i\\omega t} e^{i\\omega \\tau} \\right) \\, d\\tau \\\\\n&= \\frac{A}{2i} e^{i\\omega t} \\int_{0^-}^t h(\\tau)  e^{-i\\omega \\tau} \\, d\\tau - \\frac{A}{2i} e^{-i\\omega t} \\int_{0^-}^t h(\\tau) e^{i\\omega \\tau} \\, d\\tau\\\\\n&= \\frac{A}{2i} \\left(e^{i\\omega t}H(s) - e^{-i\\omega t} H(-s) \\right)\n\\end{align*}\\]\nWe define the frequency response function \\(H(i\\omega)\\) as the transfer function \\(H(s)\\) evaluated at \\(s=i\\omega\\).\n\\[\\left[\\frac{A}{2i} \\left(e^{i\\omega t}H(s) - e^{-i\\omega t} H(-s) \\right) \\right]_{s = i \\omega} = \\frac{A}{2i} \\left( H(i\\omega) e^{i\\omega t} - H(-i \\omega)  e^{-i\\omega t} \\right)\\]\nNotice that since the Laplace transform of the impulse response is the transfer function of a system, and the frequency response function \\(H(i\\omega)\\) is complex, we can represent it as the product of a magnitude \\(M\\) and an exponential with phase \\(\\varphi\\):\n\\[H(i\\omega) = M e^{i\\varphi}\\]\nwhere \\(M = |H(i\\omega)|\\) and \\(\\varphi = \\measuredangle H(i\\omega)\\). We rewrite \\(y(t)\\) as:\n\\[y(t) = \\frac{A}{2i} \\left(M e^{i\\omega t + \\varphi} - M e^{-i \\omega t - \\varphi} \\right) = AM \\sin(\\omega t + \\varphi)\\]\nThus, if a system has a transfer function representation of \\(H(s)\\), a sinusoidal input with amplitude \\(A\\) will “become” a sinusoidal output with magnitude \\(AM\\), shifted by phase angle \\(\\varphi\\).\nLet’s be a tad less abstract now. The frequency response is characterized as the magnitude/gain \\(M(\\omega)\\) and the phase \\(\\varphi(\\omega)\\). The magnitude is defined as the ratio of the output wave’s amplitude to the input wave’s amplitude, and the phase is defined as the offset of the output signal compared to the input signal.\nA positive magnitude means that the output wave is scaled up/magnified from the input wave. A negative magnitude means that the output wave is scaled down/contracted from the input wave. A positive phase means that the output wave leads the input wave, and a negative phase means that the output wave lags from the input wave.1"
  },
  {
    "objectID": "ch6.html#intermezzo---another-quick-dive-into-complex-analysis",
    "href": "ch6.html#intermezzo---another-quick-dive-into-complex-analysis",
    "title": "6  Frequency Response",
    "section": "Intermezzo - Another Quick Dive into Complex Analysis",
    "text": "Intermezzo - Another Quick Dive into Complex Analysis\nThinking of complex numbers as vectors is great when trying to establish the notion of a “magnitude” (or more commonly in complex analysis textbooks, the modulus) of a complex number. The magnitude \\(|z|\\) of a complex number \\(z = a + bi\\) is defined as:\n\\[|z| = |a+bi| = \\sqrt{a^2 + b^2}\\]\nA useful result for this course is that the magnitude of the product/quotient of complex numbers is equal to the product/quotient of the modulus of the complex numbers. For example:\n\\[z = \\frac{3 + i}{4 + 2i} \\qquad \\qquad |z| = \\left|\\frac{3 + i}{4 + 2i} \\right| = \\frac{\\sqrt{3^2+1^2}}{\\sqrt{4^2+2^2}} = \\sqrt{\\frac{10}{20}} = \\sqrt{\\frac{1}{2}} = \\frac{\\sqrt{2}}{2}\\]\nThe “phase” \\(\\varphi\\) (or more commonly in complex analysis textbooks, the argument) of a complex number is the polar angle from the positive real axis to the vector representation of \\(z\\) in the complex plane.\nSo say we’re interested in finding the phase of \\(z = 3 + i\\).\nIt’s clear that the phase \\(\\varphi\\) is equal to \\(\\tan^{-1} \\frac{1}{3}\\).\n(TALK ABOUT PRINCIPLE ARGUMENTS AND DOMAIN RESTRICTIONS)\nAnother useful result for this course is that the phase of the product of two complex numbers is equal to the sum of the phase of the complex numbers. (Relatedly, the phase of the quotient of two complex numbers is equal to the difference of the phase of the complex numbers.)\nSay we’re analyzing the system \\(\\dot{y} + 3y = u\\). What’s the response to the sinusoidal input \\(u = A \\cos(\\omega t)\\)?\nThe transfer function (and thus, the frequency response function) of the system is trivial to find:\n\\[H(s) = \\frac{1}{s+3} \\qquad \\qquad H(i\\omega) = \\left[H(s) \\right]_{s=i\\omega} = \\frac{1}{i\\omega + 3}\\]\n\\[M = \\left|H(i\\omega) \\right| = \\left|\\frac{1}{i\\omega + 3} \\right| = \\frac{1}{\\sqrt{\\omega^2 + 9}}\\] \\[\\varphi = \\measuredangle H(i\\omega) = -\\tan^{-1} \\left(\\frac{\\omega}{3} \\right)\\]\nNote that in the preface (and a few other times) that I specified that the frequency response only shows a system’s steady-state response. The frequency response is only applicable to the steady-state response of a system, and it does not provide information about the system’s transient behavior."
  },
  {
    "objectID": "ch6.html#its-pronounced-boh-dee",
    "href": "ch6.html#its-pronounced-boh-dee",
    "title": "6  Frequency Response",
    "section": "6.2 It’s Pronounced Boh-dee",
    "text": "6.2 It’s Pronounced Boh-dee\n(TALK ABOUT BODE AT SOME POINT)\nHow about a damped mass-spring system? Here’s the equation of motion of a hypothetical system:\n\\[\\ddot{q}+2\\zeta \\omega_n \\dot{q} + \\omega_n^2 q = \\omega_n^2 u\\]\nTo find the transfer function, we take the Laplace transform of both sides (assuming zero initial conditions) and get:\n\\[(s^2+2\\zeta\\omega_n s + \\omega_n^2) Q = \\omega_n^2 U\\] \\[H = \\frac{Q}{U} = \\frac{\\omega_n^2}{s^2+2\\zeta\\omega_n s + \\omega_n^2}\\]\n(LOOK AT INITIAL RESPONSE AND GO TO PLOTTING WITH PIECEWISE LINEARS)"
  },
  {
    "objectID": "ch6.html#footnotes",
    "href": "ch6.html#footnotes",
    "title": "6  Frequency Response",
    "section": "",
    "text": "There are opposite conventions for the sign of phase in controls and vibrations. This is because vibrations engineers usually get things wrong.↩︎"
  },
  {
    "objectID": "ch7.html#preface",
    "href": "ch7.html#preface",
    "title": "7  Dynamic Behavior and Linear Systems",
    "section": "Preface",
    "text": "Preface\nThe systems we’ve been encountering thus far have been of the form:\n\\[\\begin{equation*}\n    \\begin{cases}\n        \\boldsymbol{\\dot{\\boldsymbol{x}}} = \\boldsymbol{f}(\\boldsymbol{x}, \\boldsymbol{u})\\\\\n        \\boldsymbol{y} = \\boldsymbol{h}(\\boldsymbol{x}, \\boldsymbol{u})\n    \\end{cases}\n\\end{equation*}\\]\nWe’ve been skirting around the fact that the state-space representation of a system also allows for \\(f\\) and \\(h\\) to be nonlinear maps of \\(x\\) and \\(u\\), since we’ve been focusing on analysis of linear systems, which uses the following form:\n\\[\\begin{equation*}\n    \\begin{cases}\n        \\boldsymbol{\\dot{\\boldsymbol{x}}} = \\textbf{A} \\boldsymbol{x} + \\textbf{B} \\boldsymbol{u}\\\\\n        \\boldsymbol{y} = \\textbf{C} \\boldsymbol{x} + \\textbf{D} \\boldsymbol{u}\n    \\end{cases}\n\\end{equation*}\\]\nWell, we finally got here. First, we’ll tackle the case where \\(u\\) is itself a function of \\(x\\) (say…\\(u = \\Psi(x)\\)). In other words:\n\\[\\begin{equation*}\n    \\begin{cases}\n        \\boldsymbol{\\dot{\\boldsymbol{x}}} = \\boldsymbol{f}(\\boldsymbol{x}, \\Psi({\\boldsymbol{x}})) = \\boldsymbol{f}^*(\\boldsymbol{x}) \\\\\n        \\boldsymbol{y} = \\boldsymbol{h}(\\boldsymbol{x}, \\Psi({\\boldsymbol{x}})) = \\boldsymbol{h}^*(\\boldsymbol{x})\n    \\end{cases}\n\\end{equation*}\\]\nAs usual, the dynamic behavior of the system only really hinges on the state equation, so we’ll focus on that.\n\\[\\boldsymbol{\\dot{\\boldsymbol{x}}} = \\boldsymbol{f}(\\boldsymbol{x}, \\Psi({\\boldsymbol{x}})) = \\boldsymbol{f}^*(\\boldsymbol{x})\\]\nOur objective in this chapter is to analyze the behavior of the solutions to this equation without solving it analytically. Understanding how to determine key traits of the system without having to solve the actual differential equation is crucial to understanding how to judge the stability of a system, which is a crucial topic in control theory.\nWe also brushed over what exactly makes the state-space representation so compelling over the transfer function approach, especially since we spent so much time pouring over the Laplace transform and the frequency response. It’s honestly a bit of a tossup - the transfer function representation of a system ends up being immensely powerful for methods of classical control, but being able to navigate the state space opens the door to useful tools from linear algebra.\nWe define the phase space, also colloquially called the state space, the abstract space where the system’s states \\(x_1, x_2, ..., x_n\\) are coordinates. For now, we’ll focus on two-dimensional LTI systems so things are easier to visualize - the plane with axes \\(x_1\\) and \\(x_2\\) is known as the phase plane.\nThese two-dimensional LTI systems - also called planar dynamical systems - are sufficient to get a general idea of how qualitative analysis works. The ideas established here hold when we try to analyze dynamical behavior for systems with more state variables.\nSteven Strogatz illustrates an excellent example to develop intuition for two-dimensional systems - Romeo and Juliet. I highly recommend reading the section titled “Love Affairs” in his book on nonlinear dynamics and chaos.\n\n“I’m not Dr. Phil, or Dr. Mark, or Dr. Dirk…so don’t come to me with your relationship problems!”\nProf. Luchtenburg\n\nThat being said, before we get to two dimensions, we have to touch upon the one-dimensional case. Let’s first introduce some ideas in one dimension to beef up your intuition."
  },
  {
    "objectID": "ch7.html#panta-rei",
    "href": "ch7.html#panta-rei",
    "title": "7  Dynamic Behavior and Linear Systems",
    "section": "7.1 Panta Rei",
    "text": "7.1 Panta Rei\nYeah, Heraclitus probably didn’t say “Panta Rei”. No matter, it’s catchy, and it’s the unofficial motto of this class.\nWhen \\(\\boldsymbol{x}\\) only contains one state variable, the following equation is sufficient to describe the dynamic behavior of the system.1 (with the assumptions established in the preface to this chapter).\n\\[\\dot{x} = f^* (x)\\]\nNonlinear system are finicky - they’re usually pretty difficult to solve analytically. Alternatively, we analyze them qualitatively, using graphical methods, to map out their dynamic behavior. For the one-dimensional case, we’ve been doing this since Ma111.\nSay we’re interested in the following nonlinear system:\n\\[\\dot{x} = \\sin{x}\\]\nFirst, we’ll solve this analytically by separating the variables:\n\\[\\frac{dx}{\\sin(x)} = dt\\] \\[\\int{\\csc(x) dx} = \\int{dt}\\] \\[t = \\ln\\left|\\csc(x) + \\cot(x) \\right| + c \\]\nWhile these results are analytically correct, they’re pretty difficult to interpret. For example, provided initial conditions, how would the system behave as time elapses?\nSo rather than dealing with that…tommyrot…, we’ll graphically portray this system as a vector field, graphing \\(\\dot{x}\\) against \\(x\\).\nThere’s a bit to break down here. First, notice the arrows on the \\(x\\)-axis. If \\(\\dot{x} &gt; 0\\) (or the value of the sine wave is positive), we draw an arrow pointing in the \\(+x\\) direction. Likewise, if \\(\\dot{x} &lt; 0\\) (or the sine wave is negative), we draw an arrow pointing in the \\(-x\\) direction.\nAt points where \\(\\dot{x} = 0\\), there is no flow at all. We call these points equilibrium points. When the point is book-ended by arrows pointing towards it, we call it a stable fixed point. When the point is book-ended by arrows pointing away from it, we denote it an unstable fixed point.\nLooking back at our system, we can conclude what happens when we pick an arbitrary initial condition. For whatever \\(x_0\\) we pick:\n\nif \\(\\dot{x} &gt; 0\\), \\(x\\) will increase until it asymptotically approaches the next highest fixed point. (Say, \\(x_0 = 0.7 \\pi\\). \\(x\\) will increase until it approaches the next fixed point - \\(x = \\pi\\).)\nif \\(\\dot{x} &lt; 0\\), \\(x\\) will decrease until it asymptotically approaches the fixed point directly beneath it. (Say, \\(x_0 = 0.3 \\pi\\). \\(x\\) will decrease until it approaches the fixed point - \\(x = 0\\).)\n\nWe’ll cover this idea of stability in more detail later in the course and in ME351, but this is really just meant to give you a head start in understanding the power of ignoring the math for just a second."
  },
  {
    "objectID": "ch7.html#eigen-eigen-eigen",
    "href": "ch7.html#eigen-eigen-eigen",
    "title": "7  Dynamic Behavior and Linear Systems",
    "section": "7.2 Eigen Eigen Eigen",
    "text": "7.2 Eigen Eigen Eigen\nEigenvalue’s a scary word, and it seemingly comes up everywhere. Let’s break it down.\n\\[\\textbf{A} \\boldsymbol{v} = \\lambda \\boldsymbol{v}\\]\nis what we call an eigenproblem. \\(\\textbf{A}\\) is a square matrix, \\(\\boldsymbol{v}\\) is what we call an eigenvector, and \\(\\lambda\\) is what we call an eigenvalue. All square matrices have eigenvalues and eigenvectors.\nSo why define them? Well, eigenvectors (often shortened to e-vects) are special. When you multiply a square matrix by one of its eigenvectors, it scales that eigenvector by some constant (the eigenvalue).\nWe can solve for the eigenvalues explicitly by rearranging the eigenproblem.\n\\[\\textbf{A} \\boldsymbol{v} = \\lambda \\boldsymbol{v}\\] \\[\\textbf{A} \\boldsymbol{v} - \\lambda \\boldsymbol{v} = \\boldsymbol{0}\\] \\[(\\textbf{A} - \\lambda \\textbf{I}) \\boldsymbol{v} = \\boldsymbol{0}\\]\nThe zero vector always works as a trivial eigenvector (check it out if you don’t believe me) so we’ll omit that possibility. We have to find a nonzero \\(\\boldsymbol{v}\\) that satisfies this relation. This means that just multiplying both sides of the equation by \\((\\textbf{A} - \\lambda \\textbf{I})^{-1}\\) won’t cut it.\nBack to the eigenproblem. If we want to solve for a nonzero eigenvector, we want to find the case where the matrix \\(\\textbf{A} - \\lambda \\textbf{I}\\) is noninvertible.\nRecall that if the determinant of a matrix is 0, the matrix is noninvertible. Given a square matrix \\(\\textbf{A}\\), we define the characteristic polynomial of said matrix as \\(\\text{det}(\\textbf{A} - \\lambda \\textbf{I})\\). Following from this, we define the characteristic equation of a matrix \\(\\textbf{A}\\) as the equation \\(\\text{det}(\\textbf{A} - \\lambda \\textbf{I})=0\\).\nSuppose we wanted to find the eigenvalues of a \\(2\\times2\\) matrix \\(\\textbf{A}\\):\n\\[\\textbf{A} = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}\\]\nThe eigenvalues of \\(\\textbf{A}\\) can be solved for with the characteristic equation as follows.\n\\[\\text{det}\\left(\\textbf{A} - \\lambda \\textbf{I} \\right) = \\text{det}\\left(\\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} - \\lambda \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}\\right) = \\text{det}\\left(\\begin{bmatrix} a - \\lambda & b \\\\ c & d - \\lambda \\end{bmatrix} \\right) \\] \\[= (a-\\lambda)(d-\\lambda)-bc = 0\\]\nThe characteristic equation can alternatively be defined in terms of the trace and determinant of the \\(2\\times2\\) square matrix:2\n\\[\\lambda^2 - \\text{tr}(\\textbf{A}) \\lambda + \\text{det}(\\textbf{A}) = 0\\]\nand the eigenvalues of the matrix can be defined explicitly as the solutions of said equation.\n\\[\\lambda_{1, 2} = \\frac{\\text{tr}(\\textbf{A}) \\pm \\sqrt{(\\text{tr}(\\textbf{A}))^2 - 4 \\, \\text{det}(\\textbf{A})}}{2}\\]\nGreat, we’re halfway there. An eigenvector \\((u_1, u_2)^T\\) of the system associated with eigenvalue \\(\\lambda_k\\) will satisfy the following equation:\n\\[\\left[\\det(\\textbf{A} - \\lambda \\textbf{I}) \\right]_{\\lambda = \\lambda_k} \\begin{bmatrix}\n    u_1 \\\\\n    u_2\\end{bmatrix} = \\begin{bmatrix}\n        0 \\\\\n        0\\end{bmatrix}\\]\nLet’s give this a shot with an example - what are the eigenvalues and eigenvectors of our favorite matrix?\n\\[\\textbf{A} = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}\\]\nWe plug \\(\\textbf{A}\\) into the characteristic equation:\n\\[\\text{det}\\left(\\textbf{A} - \\lambda \\textbf{I}\\right) = \\text{det}\\left(\\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix} - \\lambda \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}\\right) = \\text{det}\\left(\\begin{bmatrix} 1 - \\lambda & 2 \\\\ 3 & 4 - \\lambda \\end{bmatrix} \\right)\\]\n\\[ = (1-\\lambda)(4-\\lambda)-(2)(3) = 0\\] \\[\\lambda^2 - 5\\lambda -2 = 0\\]\nThe solutions \\(\\lambda_1\\) and \\(\\lambda_2\\) are \\(\\textbf{A}\\)’s eigenvalues.\n\\[\\lambda_1 = \\frac{1}{2} \\left(5+\\sqrt{33} \\right) \\qquad \\qquad \\qquad \\lambda_2 = \\frac{1}{2} \\left(5 - \\sqrt{33} \\right)\\]\nNow let’s find the eigenvectors associated with these eigenvalues.\nI’m of course omitting a lot of nuance, but as always, if you want more background on eigenvalues and eigenvectors, take Ma326."
  },
  {
    "objectID": "ch7.html#so-what-about-them-poles",
    "href": "ch7.html#so-what-about-them-poles",
    "title": "7  Dynamic Behavior and Linear Systems",
    "section": "7.3 So What About Them Poles?",
    "text": "7.3 So What About Them Poles?\nWe hinted earlier that the poles of a system’s transfer function are equivalent to the eigenvalues of a system.3 Let’s prove that by converting from the state-space representation to a transfer function. (We’ll assume the system is SISO (single-input single-output) because transfer functions are only viable for SISO systems.)4\n\\[{\\dot{x}} = \\textbf{A} {x} + \\textbf{B} {u}\\]\n\\[{y} = \\textbf{C} {x} + \\textbf{D} {u}\\]\nFirst, we take the Laplace transform of each of these equations.\n\\[sX = \\textbf{A} X + \\textbf{B} U\\] \\[Y = \\textbf{C} X + \\textbf{D} U\\]\nGiven that we’re interested in finding the transfer function, we’re looking to isolate the expression equivalent to \\(H = \\frac{Y}{U}\\). To do this, we’ll isolate \\(X\\) in one of these equations and substitute it into the other.\n\\[sX = \\textbf{A} X + \\textbf{B} U\\] \\[(s\\textbf{I}-\\textbf{A}) X = \\textbf{B} U\\] \\[X = (s\\textbf{I}-\\textbf{A})^{-1} \\textbf{B} U\\]\nLooks good so far. Now, we plug \\((s\\textbf{I}-\\textbf{A})^{-1} \\textbf{B} U\\) in for \\(X\\) in the transformed output equation.\n\\[Y = \\textbf{C} (s\\textbf{I}-\\textbf{A})^{-1} \\textbf{B} U + \\textbf{D} U = (\\textbf{C} (s\\textbf{I}-\\textbf{A})^{-1} \\textbf{B} + \\textbf{D}) U\\] \\[H = \\frac{Y}{U} = \\textbf{C} (s\\textbf{I}-\\textbf{A})^{-1} \\textbf{B} + \\textbf{D}\\]\nSince the quantity \\((s\\textbf{I}-\\textbf{A})^{-1}\\) is defined as the ratio of the classical adjoint of \\((s\\textbf{I}-\\textbf{A})\\) to the determinant of \\((s\\textbf{I}-\\textbf{A})\\). Thus, the poles of \\(H(s)\\) are exactly the same as the solutions to the equation \\(\\text{det}(s\\textbf{I}-\\textbf{A}) = 0\\).\nWith a simple adjustment to how we examine the eigenproblem, we find that this equation is mathematically equivalent to how we defined the characteristic equation of \\(\\textbf{A}\\), when \\(s-\\lambda\\):\n\\[\\textbf{A} \\boldsymbol{v} = \\lambda \\boldsymbol{v}\\] \\[\\boldsymbol{0} = \\lambda \\boldsymbol{v} - \\textbf{A} \\boldsymbol{v}\\] \\[\\boldsymbol{0} = (\\lambda \\textbf{I} - \\textbf{A}) \\boldsymbol{v}\\] \\[\\text{det}(\\lambda \\textbf{I} - \\textbf{A}) \\boldsymbol{v} = 0\\]\nThese definitions of the characteristic equation are functionally the same for our purposes; they differ by a factor of \\((-1)^n\\), (where \\(n\\) is the row/column length of square matrix \\(A\\)) which has no bearing on the roots of the equation.\nThis means that the poles of the system is solely dependent on \\(\\textbf{A}\\). (More generally, the stability of the whole system solely hinges on \\(\\textbf{A}\\).)"
  },
  {
    "objectID": "ch7.html#state-transition-matrices-and-the-matrix-exponential",
    "href": "ch7.html#state-transition-matrices-and-the-matrix-exponential",
    "title": "7  Dynamic Behavior and Linear Systems",
    "section": "7.4 State Transition Matrices and the Matrix Exponential",
    "text": "7.4 State Transition Matrices and the Matrix Exponential"
  },
  {
    "objectID": "ch7.html#linearization",
    "href": "ch7.html#linearization",
    "title": "7  Dynamic Behavior and Linear Systems",
    "section": "7.5 Linearization",
    "text": "7.5 Linearization\nLinearization is an art. Sure, understanding the behavior of nonlinear systems qualitatively is cool and all, but nothing really compares to the beauty of an analytical solution.\nThat being said, as we’ve established earlier in the chapter, nonlinear systems are difficult to solve. However, if we simplify the problem so that a solution that applies near a point of interest suffices, our life becomes much easier.\nA notable example of where we’ve encountered the idea of linearization before is the idea of a small-angle approximation, where:\n\\[\\sin(\\theta) \\approx \\theta \\qquad \\qquad \\cos(\\theta) \\approx 1\\]\nfor small \\(\\theta\\)’s.\nFirst, let’s tackle the idea of a one-dimensional linearization (or as we called it in Ma111, a linear approximation). For an arbitrary function \\(y = f(x)\\), if \\(f\\) is differentiable at a point \\(x_0\\), the tangent line at \\(x=x_0\\) passes through the point \\(x_0, f(x_0)\\). This leads to the point-slope form of the tangent line at that point:\n\\[y = f'(x_0) (x-x_0) + f(x_0)\\]\nObserve that so long as \\(x_0 \\approx x\\), the linearization \\(y\\) will yield a close approximation to the true value of \\(f\\) at \\(x = x_0\\). As our choice of \\(x\\) shifts further from \\(x_0\\), the accuracy of our approximation gets lousier and lousier.\nWhen we push forward from one dimension onwards, the path becomes murkier. If our objective is to develop control schemes for nonlinear dynamical systems based on linear models, it isn’t really useful to linearize about any old point anymore. Rather, we select one of the nonlinear system’s equilibrium points to linearize around.5\nNote that a nonlinear system can have many equilibrium points, and that each can have a different linearization associated with it.\nLet’s take a look at a general SISO nonlinear system, defined as follows:\n\\[\\begin{equation*}\n    \\left\\{ \\begin{array}{ll}\n        \\dot{x} = f(x, u) \\\\\n        y = h(x, u)\n    \\end{array} \\right.\n\\end{equation*}\\]\nwith an equilibrium point at \\(x = x_e\\) and \\(u = u_e\\). So long as \\(x - x_e\\) and \\(u - u_e\\) are very tiny, we can reliably study the local behavior of the system for \\((x,u)\\) around the equilibrium points.\nWe define a new state variable \\(z = x-x_e\\), a new input \\(v = u-u_e\\), and a new output \\(w = y - h(x_e, u_e)\\), and rewrite the nonlinear system in terms of these deviations.\n\\[\\begin{equation*}\n    \\left\\{ \\begin{array}{ll}\n        \\dot{z} = f(x_e + z, u_e + v)\\\\\n        w = h(x_e + z, u_e + v) - h(x_e, u_e)\n    \\end{array} \\right.\n\\end{equation*}\\]\nNow, we use the same linear approximations we used in the one-dimensional case:\n\\[f(x_e + z, u_e + v) \\approx \\left[\\frac{\\partial f}{\\partial x} \\right]_{(x_e, u_e)} z + \\left[\\frac{\\partial f}{\\partial u} \\right]_{(x_e, u_e)} v + f(x_e, u_e)\\] \\[h(x_e + z, u_e + v) \\approx \\left[\\frac{\\partial h}{\\partial x} \\right]_{(x_e, u_e)} z + \\left[\\frac{\\partial h}{\\partial u} \\right]_{(x_e, u_e)} v + h(x_e, u_e)\\]\nSince \\(\\dot{x} = f(x_e, u_e) = 0\\) and \\(w = h(x_e + z, u_e + v) - h(x_e, u_e)\\) at equilibrium, we can reorganize these equations into the following linear form.\n\\[\\begin{equation*}\n    \\begin{cases}\n        \\dot{z} = \\left[\\frac{\\partial f}{\\partial x} \\right]_{(x_e, u_e)} z + \\left[\\frac{\\partial f}{\\partial u} \\right]_{(x_e, u_e)} v = Az + Bv\\\\\n        w = \\left[\\frac{\\partial h}{\\partial x} \\right]_{(x_e, u_e)} z + \\left[\\frac{\\partial h}{\\partial u} \\right]_{(x_e, u_e)} v = Cz + Dv\n    \\end{cases}\n\\end{equation*}\\]\nWe define the Jacobian linearization of a system as:\n\\[\\begin{equation*}\n    \\begin{cases}\n        \\dot{z} = Az + Bv \\\\\n        w = Cz + Dv\n    \\end{cases}\n\\end{equation*}\\]\nThis definition is easily generalizable when there are multiple inputs and multiple outputs - just add vector dashes and bold your matrices!6\n\\[\\begin{equation*}\n    \\begin{cases}\n        \\dot{\\boldsymbol{z}} = \\textbf{A}\\boldsymbol{z} + \\textbf{B}\\boldsymbol{v} \\\\\n        \\boldsymbol{w} = \\textbf{C}\\boldsymbol{z} + \\textbf{D}\\boldsymbol{v}\n    \\end{cases}\n\\end{equation*}\\]"
  },
  {
    "objectID": "ch7.html#modal-decomposition",
    "href": "ch7.html#modal-decomposition",
    "title": "7  Dynamic Behavior and Linear Systems",
    "section": "7.6 Modal Decomposition",
    "text": "7.6 Modal Decomposition"
  },
  {
    "objectID": "ch7.html#footnotes",
    "href": "ch7.html#footnotes",
    "title": "7  Dynamic Behavior and Linear Systems",
    "section": "",
    "text": "Some of you might be wary about the usage of the word “system” to describe one equation. We’ll adhere to the definitions established by Steven Strogatz, where the word “system” is used in the context of dynamical systems, not as a collection of more than one equation.↩︎\nPretty easily verifiable, give it a go!↩︎\nNotably, this is NOT the case if the transfer function has pole-zero cancellation or the state-space representation isn’t controllable and observable. This is a ME351 caveat though, we should be fine for now.↩︎\nNumerator is output and denominator is input. There’s methods to consider MIMO (multiple-input multiple-output) systems as well using something called a transfer function matrix, but that’s a story for another day.↩︎\nIf this is a bit too hand-wavey for you, there’s a theorem called the Hartman–Grobman theorem that posits that the local behavior of a dynamical system near an equilibrium point with \\(\\text{Re}(\\lambda) \\neq 0\\) is functionally equivalent to that of a linearization about that equilibrium point.↩︎\nRemind me to come back here and talk about trim at some point.↩︎"
  },
  {
    "objectID": "chaux.html#a-quick-and-dirty-introduction-to-control",
    "href": "chaux.html#a-quick-and-dirty-introduction-to-control",
    "title": "8  Auxiliary Topics",
    "section": "8.1 A Quick and Dirty Introduction to Control",
    "text": "8.1 A Quick and Dirty Introduction to Control"
  },
  {
    "objectID": "chaux.html#too-many-blocks",
    "href": "chaux.html#too-many-blocks",
    "title": "8  Auxiliary Topics",
    "section": "8.2 Too Many Blocks!",
    "text": "8.2 Too Many Blocks!"
  },
  {
    "objectID": "chaux.html#the-singular-value-decomposition",
    "href": "chaux.html#the-singular-value-decomposition",
    "title": "8  Auxiliary Topics",
    "section": "8.3 The Singular Value Decomposition",
    "text": "8.3 The Singular Value Decomposition"
  }
]